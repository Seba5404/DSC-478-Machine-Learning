{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sebastian Zdarowski \n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Sebastian/Graduate School/DSC - 478 Machine Learning /HW/HW 3/newsgroups5'"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get working directory\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change working directory\n",
    "os.chdir('/Users/Sebastian/Graduate School/DSC - 478 Machine Learning /HW/HW 3/communities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state        communityname  population  householdsize  racepctblack  \\\n",
       "0      8         Lakewoodcity        0.19           0.33          0.02   \n",
       "1     53          Tukwilacity        0.00           0.16          0.12   \n",
       "2     24         Aberdeentown        0.00           0.42          0.49   \n",
       "3     34  Willingborotownship        0.04           0.77          1.00   \n",
       "4     42    Bethlehemtownship        0.01           0.55          0.02   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  \\\n",
       "0          0.90          0.12         0.17         0.34         0.47   \n",
       "1          0.74          0.45         0.07         0.26         0.59   \n",
       "2          0.56          0.17         0.04         0.39         0.47   \n",
       "3          0.08          0.12         0.10         0.51         0.50   \n",
       "4          0.95          0.09         0.05         0.38         0.38   \n",
       "\n",
       "          ...           NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "0         ...                 0.0            0.12              0.42   \n",
       "1         ...                 0.0            0.21              0.50   \n",
       "2         ...                 0.0            0.14              0.49   \n",
       "3         ...                 0.0            0.19              0.30   \n",
       "4         ...                 0.0            0.11              0.72   \n",
       "\n",
       "   PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "0            0.50           0.51            0.64      0.12     0.26   \n",
       "1            0.34           0.60            0.52      0.02     0.12   \n",
       "2            0.54           0.67            0.56      0.01     0.21   \n",
       "3            0.73           0.64            0.65      0.02     0.39   \n",
       "4            0.64           0.61            0.53      0.04     0.09   \n",
       "\n",
       "   PctUsePubTrans  ViolentCrimesPerPop  \n",
       "0            0.20                 0.20  \n",
       "1            0.45                 0.67  \n",
       "2            0.02                 0.43  \n",
       "3            0.28                 0.12  \n",
       "4            0.02                 0.03  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#populate data into dataframe\n",
    "ComData = pd.read_csv(\"communities.csv\", sep=',')\n",
    "ComData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 100)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Jacksonvillecity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.683551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057593</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.179629</td>\n",
       "      <td>0.753716</td>\n",
       "      <td>0.153681</td>\n",
       "      <td>0.144022</td>\n",
       "      <td>0.424218</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.215552</td>\n",
       "      <td>0.608892</td>\n",
       "      <td>0.535050</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.651530</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>0.232854</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>0.237979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.397553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.244039</td>\n",
       "      <td>0.208877</td>\n",
       "      <td>0.232492</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.204329</td>\n",
       "      <td>0.181352</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.198221</td>\n",
       "      <td>0.109459</td>\n",
       "      <td>0.203092</td>\n",
       "      <td>0.229055</td>\n",
       "      <td>0.232985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              state     communityname   population  householdsize  \\\n",
       "count   1994.000000              1994  1994.000000    1994.000000   \n",
       "unique          NaN              1828          NaN            NaN   \n",
       "top             NaN  Jacksonvillecity          NaN            NaN   \n",
       "freq            NaN                 5          NaN            NaN   \n",
       "mean      28.683551               NaN     0.057593       0.463395   \n",
       "std       16.397553               NaN     0.126906       0.163717   \n",
       "min        1.000000               NaN     0.000000       0.000000   \n",
       "25%       12.000000               NaN     0.010000       0.350000   \n",
       "50%       34.000000               NaN     0.020000       0.440000   \n",
       "75%       42.000000               NaN     0.050000       0.540000   \n",
       "max       56.000000               NaN     1.000000       1.000000   \n",
       "\n",
       "        racepctblack  racePctWhite  racePctAsian  racePctHisp  agePct12t21  \\\n",
       "count    1994.000000   1994.000000   1994.000000  1994.000000  1994.000000   \n",
       "unique           NaN           NaN           NaN          NaN          NaN   \n",
       "top              NaN           NaN           NaN          NaN          NaN   \n",
       "freq             NaN           NaN           NaN          NaN          NaN   \n",
       "mean        0.179629      0.753716      0.153681     0.144022     0.424218   \n",
       "std         0.253442      0.244039      0.208877     0.232492     0.155196   \n",
       "min         0.000000      0.000000      0.000000     0.000000     0.000000   \n",
       "25%         0.020000      0.630000      0.040000     0.010000     0.340000   \n",
       "50%         0.060000      0.850000      0.070000     0.040000     0.400000   \n",
       "75%         0.230000      0.940000      0.170000     0.160000     0.470000   \n",
       "max         1.000000      1.000000      1.000000     1.000000     1.000000   \n",
       "\n",
       "        agePct12t29         ...             NumStreet  PctForeignBorn  \\\n",
       "count   1994.000000         ...           1994.000000     1994.000000   \n",
       "unique          NaN         ...                   NaN             NaN   \n",
       "top             NaN         ...                   NaN             NaN   \n",
       "freq            NaN         ...                   NaN             NaN   \n",
       "mean       0.493867         ...              0.022778        0.215552   \n",
       "std        0.143564         ...              0.100400        0.231134   \n",
       "min        0.000000         ...              0.000000        0.000000   \n",
       "25%        0.410000         ...              0.000000        0.060000   \n",
       "50%        0.480000         ...              0.000000        0.130000   \n",
       "75%        0.540000         ...              0.000000        0.280000   \n",
       "max        1.000000         ...              1.000000        1.000000   \n",
       "\n",
       "        PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  \\\n",
       "count        1994.000000     1994.000000    1994.000000     1994.000000   \n",
       "unique               NaN             NaN            NaN             NaN   \n",
       "top                  NaN             NaN            NaN             NaN   \n",
       "freq                 NaN             NaN            NaN             NaN   \n",
       "mean            0.608892        0.535050       0.626424        0.651530   \n",
       "std             0.204329        0.181352       0.200521        0.198221   \n",
       "min             0.000000        0.000000       0.000000        0.000000   \n",
       "25%             0.470000        0.420000       0.520000        0.560000   \n",
       "50%             0.630000        0.540000       0.670000        0.700000   \n",
       "75%             0.777500        0.660000       0.770000        0.790000   \n",
       "max             1.000000        1.000000       1.000000        1.000000   \n",
       "\n",
       "           LandArea      PopDens  PctUsePubTrans  ViolentCrimesPerPop  \n",
       "count   1994.000000  1994.000000     1994.000000          1994.000000  \n",
       "unique          NaN          NaN             NaN                  NaN  \n",
       "top             NaN          NaN             NaN                  NaN  \n",
       "freq            NaN          NaN             NaN                  NaN  \n",
       "mean       0.065231     0.232854        0.161685             0.237979  \n",
       "std        0.109459     0.203092        0.229055             0.232985  \n",
       "min        0.000000     0.000000        0.000000             0.000000  \n",
       "25%        0.020000     0.100000        0.020000             0.070000  \n",
       "50%        0.040000     0.170000        0.070000             0.150000  \n",
       "75%        0.070000     0.280000        0.190000             0.330000  \n",
       "max        1.000000     1.000000        1.000000             1.000000  \n",
       "\n",
       "[11 rows x 100 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute and display basic statistics (mean, standard deviation, min, max, etc.) \n",
    "#for each of the variables in the data set.\n",
    "ComData.describe(include=\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle missing data\n",
    "np.sum(np.array(pd.isnull(ComData)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                      int64\n",
       "communityname             object\n",
       "population               float64\n",
       "householdsize            float64\n",
       "racepctblack             float64\n",
       "racePctWhite             float64\n",
       "racePctAsian             float64\n",
       "racePctHisp              float64\n",
       "agePct12t21              float64\n",
       "agePct12t29              float64\n",
       "agePct16t24              float64\n",
       "agePct65up               float64\n",
       "numbUrban                float64\n",
       "pctUrban                 float64\n",
       "medIncome                float64\n",
       "pctWWage                 float64\n",
       "pctWFarmSelf             float64\n",
       "pctWInvInc               float64\n",
       "pctWSocSec               float64\n",
       "pctWPubAsst              float64\n",
       "pctWRetire               float64\n",
       "medFamInc                float64\n",
       "perCapInc                float64\n",
       "whitePerCap              float64\n",
       "blackPerCap              float64\n",
       "indianPerCap             float64\n",
       "AsianPerCap              float64\n",
       "OtherPerCap               object\n",
       "HispPerCap               float64\n",
       "NumUnderPov              float64\n",
       "                          ...   \n",
       "MedNumBR                 float64\n",
       "HousVacant               float64\n",
       "PctHousOccup             float64\n",
       "PctHousOwnOcc            float64\n",
       "PctVacantBoarded         float64\n",
       "PctVacMore6Mos           float64\n",
       "MedYrHousBuilt           float64\n",
       "PctHousNoPhone           float64\n",
       "PctWOFullPlumb           float64\n",
       "OwnOccLowQuart           float64\n",
       "OwnOccMedVal             float64\n",
       "OwnOccHiQuart            float64\n",
       "RentLowQ                 float64\n",
       "RentMedian               float64\n",
       "RentHighQ                float64\n",
       "MedRent                  float64\n",
       "MedRentPctHousInc        float64\n",
       "MedOwnCostPctInc         float64\n",
       "MedOwnCostPctIncNoMtg    float64\n",
       "NumInShelters            float64\n",
       "NumStreet                float64\n",
       "PctForeignBorn           float64\n",
       "PctBornSameState         float64\n",
       "PctSameHouse85           float64\n",
       "PctSameCity85            float64\n",
       "PctSameState85           float64\n",
       "LandArea                 float64\n",
       "PopDens                  float64\n",
       "PctUsePubTrans           float64\n",
       "ViolentCrimesPerPop      float64\n",
       "Length: 100, dtype: object"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComData.dtypes #look at datatypes to make sure we are only including numeric values \n",
    "#OtherPerCap stands out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communityname</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>householdsize</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racepctblack</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctWhite</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctAsian</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctHisp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct12t21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct12t29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct16t24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct65up</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numbUrban</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctUrban</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medIncome</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWWage</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWInvInc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWSocSec</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWRetire</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medFamInc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perCapInc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitePerCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blackPerCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indianPerCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AsianPerCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OtherPerCap</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HispPerCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumUnderPov</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedNumBR</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HousVacant</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousOccup</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousOwnOcc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctVacantBoarded</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctVacMore6Mos</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedYrHousBuilt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousNoPhone</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctWOFullPlumb</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccLowQuart</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccMedVal</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccHiQuart</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentLowQ</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentMedian</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentHighQ</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedRent</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedRentPctHousInc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInShelters</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumStreet</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctBornSameState</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameCity85</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameState85</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandArea</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PopDens</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "state                  0\n",
       "communityname          0\n",
       "population             0\n",
       "householdsize          0\n",
       "racepctblack           0\n",
       "racePctWhite           0\n",
       "racePctAsian           0\n",
       "racePctHisp            0\n",
       "agePct12t21            0\n",
       "agePct12t29            0\n",
       "agePct16t24            0\n",
       "agePct65up             0\n",
       "numbUrban              0\n",
       "pctUrban               0\n",
       "medIncome              0\n",
       "pctWWage               0\n",
       "pctWFarmSelf           0\n",
       "pctWInvInc             0\n",
       "pctWSocSec             0\n",
       "pctWPubAsst            0\n",
       "pctWRetire             0\n",
       "medFamInc              0\n",
       "perCapInc              0\n",
       "whitePerCap            0\n",
       "blackPerCap            0\n",
       "indianPerCap           0\n",
       "AsianPerCap            0\n",
       "OtherPerCap            1\n",
       "HispPerCap             0\n",
       "NumUnderPov            0\n",
       "...                   ..\n",
       "MedNumBR               0\n",
       "HousVacant             0\n",
       "PctHousOccup           0\n",
       "PctHousOwnOcc          0\n",
       "PctVacantBoarded       0\n",
       "PctVacMore6Mos         0\n",
       "MedYrHousBuilt         0\n",
       "PctHousNoPhone         0\n",
       "PctWOFullPlumb         0\n",
       "OwnOccLowQuart         0\n",
       "OwnOccMedVal           0\n",
       "OwnOccHiQuart          0\n",
       "RentLowQ               0\n",
       "RentMedian             0\n",
       "RentHighQ              0\n",
       "MedRent                0\n",
       "MedRentPctHousInc      0\n",
       "MedOwnCostPctInc       0\n",
       "MedOwnCostPctIncNoMtg  0\n",
       "NumInShelters          0\n",
       "NumStreet              0\n",
       "PctForeignBorn         0\n",
       "PctBornSameState       0\n",
       "PctSameHouse85         0\n",
       "PctSameCity85          0\n",
       "PctSameState85         0\n",
       "LandArea               0\n",
       "PopDens                0\n",
       "PctUsePubTrans         0\n",
       "ViolentCrimesPerPop    0\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComData.OtherPerCap = pd.to_numeric(ComData.OtherPerCap, errors='coerce')\n",
    "#ComData.dtypes\n",
    "#Check for N/As\n",
    "CheckNa = pd.DataFrame(ComData.isnull().sum(0))\n",
    "CheckNa\n",
    "#othercap still has na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#replace N.A with mean value for othercap \n",
    "othercap = ComData.OtherPerCap.mean()\n",
    "ComData.OtherPerCap.fillna(othercap, axis = 0, inplace = True)\n",
    "\n",
    "#CheckNa = pd.DataFrame(ComData.isnull().sum(0))\n",
    "#CheckNa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target attribute for regression.\n",
    "\n",
    "#per dataset info the attribute to be predicted (Per Capita Violent Crimes).\n",
    "\n",
    "targetY = ComData['ViolentCrimesPerPop']\n",
    "#Seperate attributes\n",
    "\n",
    "#-- state: US state (by number) - not counted as predictive above, but if considered, should be considerd nominal (nominal)\n",
    "#-- county: numeric code for county - not predictive, and many missing values (numeric)\n",
    "#Drop State and Community names since they are not considered predictive.. \n",
    "\n",
    "F_ComData = ComData.drop(['state', 'communityname', 'ViolentCrimesPerPop'], axis = 1, inplace = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.20\n",
       "1    0.67\n",
       "2    0.43\n",
       "3    0.12\n",
       "4    0.03\n",
       "Name: ViolentCrimesPerPop, dtype: float64"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetY.shape\n",
    "targetY.head() #check target varible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 97)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_ComData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1B code from PG 157 Chapter 8 MLA as requsted to be used through assignment. \n",
    "\n",
    "def standRegres(xArr, yArr):\n",
    "    xMat = np.matrix(xArr) ; yMat = np.matrix(yArr).T\n",
    "    xTx = xMat.T*xMat\n",
    "    if np.linalg.det(xTx) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "    else:\n",
    "        ws = xTx.I * (xMat.T*yMat)\n",
    "        return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to do multiple regression we need to add a column of 1s for x0\n",
    "\n",
    "xData = np.array(F_ComData)\n",
    "x = np.array([np.concatenate((v,[1])) for v in xData])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.31108068e-01],\n",
       "        [-3.14114977e-02],\n",
       "        [ 2.09909670e-01],\n",
       "        [-4.05351612e-02],\n",
       "        [-1.38892919e-02],\n",
       "        [ 5.89726825e-02],\n",
       "        [ 1.23399025e-01],\n",
       "        [-2.22621600e-01],\n",
       "        [-1.47500199e-01],\n",
       "        [ 5.01635477e-02],\n",
       "        [-2.42413829e-01],\n",
       "        [ 4.64024392e-02],\n",
       "        [-1.96945615e-01],\n",
       "        [-2.06117500e-01],\n",
       "        [ 4.65935490e-02],\n",
       "        [-1.77212915e-01],\n",
       "        [ 6.30148504e-02],\n",
       "        [ 1.14942190e-02],\n",
       "        [-9.08951848e-02],\n",
       "        [ 2.74640044e-01],\n",
       "        [ 1.01752476e-01],\n",
       "        [-3.31517562e-01],\n",
       "        [-2.91799268e-02],\n",
       "        [-3.54483393e-02],\n",
       "        [ 2.26173855e-02],\n",
       "        [ 4.30950137e-02],\n",
       "        [ 3.44408548e-02],\n",
       "        [ 1.28412458e-01],\n",
       "        [-1.91293360e-01],\n",
       "        [-1.00769002e-01],\n",
       "        [ 6.46856092e-02],\n",
       "        [ 1.06062117e-01],\n",
       "        [ 2.44125993e-06],\n",
       "        [ 2.34984611e-01],\n",
       "        [-3.75705330e-02],\n",
       "        [-7.74957660e-03],\n",
       "        [ 4.66779619e-01],\n",
       "        [ 2.26295907e-01],\n",
       "        [ 1.74621953e-01],\n",
       "        [-5.75206227e-01],\n",
       "        [-1.41954207e-01],\n",
       "        [ 5.68782538e-02],\n",
       "        [-3.51066745e-01],\n",
       "        [-3.49493414e-02],\n",
       "        [ 4.63705978e-04],\n",
       "        [ 5.57016681e-02],\n",
       "        [-1.82238360e-01],\n",
       "        [-1.54646442e-01],\n",
       "        [ 1.26172899e-01],\n",
       "        [-1.44320569e-01],\n",
       "        [ 2.39071713e-02],\n",
       "        [ 3.33390229e-02],\n",
       "        [-7.42297409e-02],\n",
       "        [ 3.59876412e-02],\n",
       "        [-3.31691535e-02],\n",
       "        [-2.18174916e-01],\n",
       "        [ 4.45777391e-01],\n",
       "        [-2.00030978e-01],\n",
       "        [-2.67307658e-02],\n",
       "        [-1.41457254e-01],\n",
       "        [ 6.38133109e-02],\n",
       "        [-2.10115806e-01],\n",
       "        [ 6.51276465e-01],\n",
       "        [-8.02774919e-02],\n",
       "        [-2.53817057e-01],\n",
       "        [-6.66334925e-01],\n",
       "        [ 2.01002575e-01],\n",
       "        [ 1.03326247e-01],\n",
       "        [ 2.88599766e-02],\n",
       "        [ 1.68314795e-01],\n",
       "        [-4.00752791e-02],\n",
       "        [ 5.53867355e-01],\n",
       "        [ 4.70396419e-02],\n",
       "        [-7.64314747e-02],\n",
       "        [-2.89277350e-02],\n",
       "        [ 1.40739015e-02],\n",
       "        [-1.40629951e-02],\n",
       "        [-3.46854609e-01],\n",
       "        [ 2.67796471e-01],\n",
       "        [ 1.19446906e-02],\n",
       "        [-2.36996317e-01],\n",
       "        [-2.60764386e-02],\n",
       "        [-6.84041742e-02],\n",
       "        [ 3.74730887e-01],\n",
       "        [ 4.17402525e-02],\n",
       "        [-4.45747318e-02],\n",
       "        [-8.34683479e-02],\n",
       "        [ 1.30736305e-01],\n",
       "        [ 1.83468559e-01],\n",
       "        [ 1.26046949e-01],\n",
       "        [ 4.63490658e-03],\n",
       "        [-2.24577196e-02],\n",
       "        [ 2.88627319e-02],\n",
       "        [ 1.30622513e-02],\n",
       "        [ 2.76170980e-02],\n",
       "        [-1.24479622e-02],\n",
       "        [-3.73099899e-02],\n",
       "        [ 5.88079813e-01]])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearStandRegress = standRegres(x,targetY)\n",
    "#run linear standard regression using mla code \n",
    "linearStandRegress #print out matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE calculation \n",
    "\n",
    "# Create linear regression object, taken from regression notebook presented in class. \n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "linreg.fit(x,targetY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE on training data\n",
    "p = linreg.predict(x)\n",
    "\n",
    "# Now we can constuct a vector of errors\n",
    "err = abs(p-targetY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12888960779787606\n"
     ]
    }
   ],
   "source": [
    "# Dot product of error vector with itself gives us the sum of squared errors\n",
    "total_error = np.dot(err,err)\n",
    "\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "print (rmse_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Coefficients: \n",
      " [ 1.31108068e-01 -3.14114977e-02  2.09909670e-01 -4.05351612e-02\n",
      " -1.38892919e-02  5.89726825e-02  1.23399025e-01 -2.22621600e-01\n",
      " -1.47500199e-01  5.01635477e-02 -2.42413829e-01  4.64024392e-02\n",
      " -1.96945615e-01 -2.06117500e-01  4.65935490e-02 -1.77212915e-01\n",
      "  6.30148504e-02  1.14942190e-02 -9.08951848e-02  2.74640044e-01\n",
      "  1.01752476e-01 -3.31517562e-01 -2.91799268e-02 -3.54483393e-02\n",
      "  2.26173855e-02  4.30950137e-02  3.44408548e-02  1.28412458e-01\n",
      " -1.91293360e-01 -1.00769002e-01  6.46856092e-02  1.06062117e-01\n",
      "  2.44125996e-06  2.34984611e-01 -3.75705330e-02 -7.74957660e-03\n",
      "  4.66779619e-01  2.26295907e-01  1.74621953e-01 -5.75206227e-01\n",
      " -1.41954207e-01  5.68782538e-02 -3.51066745e-01 -3.49493414e-02\n",
      "  4.63705978e-04  5.57016681e-02 -1.82238360e-01 -1.54646442e-01\n",
      "  1.26172899e-01 -1.44320569e-01  2.39071713e-02  3.33390229e-02\n",
      " -7.42297409e-02  3.59876412e-02 -3.31691535e-02 -2.18174916e-01\n",
      "  4.45777391e-01 -2.00030978e-01 -2.67307658e-02 -1.41457254e-01\n",
      "  6.38133109e-02 -2.10115806e-01  6.51276465e-01 -8.02774919e-02\n",
      " -2.53817057e-01 -6.66334925e-01  2.01002575e-01  1.03326247e-01\n",
      "  2.88599766e-02  1.68314795e-01 -4.00752791e-02  5.53867355e-01\n",
      "  4.70396419e-02 -7.64314747e-02 -2.89277350e-02  1.40739015e-02\n",
      " -1.40629951e-02 -3.46854609e-01  2.67796471e-01  1.19446906e-02\n",
      " -2.36996317e-01 -2.60764386e-02 -6.84041742e-02  3.74730887e-01\n",
      "  4.17402525e-02 -4.45747318e-02 -8.34683479e-02  1.30736305e-01\n",
      "  1.83468559e-01  1.26046949e-01  4.63490658e-03 -2.24577196e-02\n",
      "  2.88627319e-02  1.30622513e-02  2.76170980e-02 -1.24479622e-02\n",
      " -3.73099899e-02  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "#Display the obtained regression coefficients (weights)\n",
    "#view the regression coefficients\n",
    "print ('Regression Coefficients: \\n', linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXl8VNX1wL83k0RIAJEBV0xwgVq1bmCValXEBalVi0vVsAgIEluXn7UWilWqpVVbtdYqi4oiifu+b6h1X0AElxaKCohQRXADZM35/fFmksnkrTPvzZKc7+dzP5l5c999572Z3HPvOeeea0QERVEURQEoybcAiqIoSuGgSkFRFEVpRJWCoiiK0ogqBUVRFKURVQqKoihKI6oUFEVRlEZUKSiKoiiNqFJQFEVRGlGloCiKojRSmm8BgtK1a1fp0aNHvsVQFEUpKmbPnv2liHTzqld0SqFHjx7MmjUr32IoiqIUFcaYxX7qqflIURRFaUSVgqIoitKIKgVFURSlEVUKiqIoSiOqFBRFUZRGVCkoiqIojahSUBRFURpRpaAoilLgbG7YzF9e/guzl82O/FpFt3hNURSlLfHpN58y+MHBvLT4Jb5Z/w29t+8d6fVUKSiKohQo935wL6MfG82mhk1MP2E6Q/YaEvk1VSkoiqIUGKs3rObcJ8/l1ndv5YAdDqB+UD27dNklJ9dWpaAoilJAvP3Z25z+wOl8tOojxv90PJceeillsbKcXV+VgqIoSgGwuWEzf33tr/zhhT+wXYftePGMFzmk+pCcy6FKQVEUJc8s/XYpQx4cwouLXuSUPU5h8s8ms1X7rfIiiyoFRVGUPHL/h/cz6tFRbNi8gVuPv5Vhew/DGJM3eVQpKIqi5IHVG1Zz/lPnc8ucW9h/+/2548Q72LXLrvkWS5WCoihKrpm9bDan3X8aC1ct5PcH/54Jh03IqTPZDVUKiqIoOaJBGvjba3/j4ucvZpsO2/D8sOc5rMdh+RarGaoUFEVRcsBn337G0IeG8vwnz3PS7icx5dgpdGnfJd9itUCVgqIoSsQ8+O8HOfPRM1m/aT23HHcLw/cZnldnshuRJcQzxkwzxnxhjHnf4fMaY8y8RHnNGLN3VLIoiqLkgzUb1jD60dEMumcQO2+1M3POmsOIfUcUrEKAaLOk3gYMcPn8E+BQEdkLuByYGqEsiqIoOeWd5e/Qe2pvbn7nZsYeNJZXR7xKz3jPfIvlSWTmIxF5yRjTw+Xz11LevgF0j0oWRVGUXNEgDVzz+jX8fubv2bpya2YOnUm/nfrlWyzfFIpPYSTwpNOHxpjRwGiAqqqqXMmkKIoSiGXfLWPYQ8N47uPnGPTDQUw9dirxini+xQpE3pWCMaYfllI42KmOiEwlYV7q06eP5Eg0RVEU3zz8n4cZ+chIvt/0PTf9/CZG7juyoH0HTuRVKRhj9gJuBo4RkZX5lEVRFCUT1m5cywVPX8CU2VPYb7v9uGPQHfyg6w/yLVbG5E0pGGOqgAeAISKyIF9yKIqiZMqc5XM4/YHTmf/lfC76yUVcfvjllMfK8y1WVkSmFIwxdwKHAV2NMUuBS4EyABGZDFwCxIEbE1OsTSLSJyp5FEVRwqJBGrj29WsZN3Mc3Sq78eyQZ+m/c/98ixUKUUYfnebx+ZnAmVFdX1EUJQqWf7ecYQ8N49mPn+WE3U7g5p/fXHTOZDfy7mhWFEUpFh6d/ygjHhnBmg1rmHLsFEbtN6ooncluqFJQFEXxYO3GtVz4zIVMmjWJfbfdlztOvIPduu6Wb7EiQZWCoiiKC3P/N5fT7j+Nf3/5by7seyF/OvxPbFG6Rb7FigxVCoqiKDY0SAPXvXEdY2eOJd4+zjODn+HIXY7Mt1iRo0pBURQljf+t/h9nPHQGT3/0NMf94DhuOe4WulZ0zbdYOUGVgqIoSgqPL3ic4Q8PZ/WG1Uz62STO6n1Wq3Mmu6FKQVEUBfh+4/f89tnfcsPbN7D3Nntz54l38sNuP8y3WDlHlYKiKG2e9z5/j9PuP40PVnzA/x34f/yl/19atTPZDVUKiqK0WUSE69+6nouevYit2m/F04Of5qhdjsq3WHlFlYKiKG2Sz1d/zvCHh/Pkwic5ttexTDtuGt0qu+VbrLyjSkFRlDbHE/99guEPD+fb9d9yw8AbqO1T26acyW6oUlAUpc2wbtM6fvfs7/jHW//gR1v/iOeHPs8eW++Rb7EKClUKiqK0Cd7/4n1Ov/903vviPc474DyuOOIK2pW2y7dYBYcqBUVRWjUiwg1v38CFz1xI53adebLmSQbsOiDfYhUsqhQURWm1fLHmC0Y8PILH//s4A3sO5Nbjb2Xryq3zLVZBo0pBUZRWyVMLn+KMh87g63Vfc/0x1/Or/X+lzmQfqFJQFKVVsW7TOsY9N46/v/l39tx6T54b+hx7br1nvsUqGlQpKIrSavhwxYecdv9pzPt8Huf8+ByuPOJK2pe1z7dYRYUqBUVRih4RYdKsSfzmmd/QaYtOPH665UNQgqNKQVGUombFmhWMfGQkjy54lGN2PYZbj7+VbTpsk2+xihZVCoqiFC3PfPQMwx4axlfff8V1A67jnB+fo87kLCmJqmFjzDRjzBfGmPcdPjfGmH8YYxYaY+YZY/aLShZFUVoX6zet54KnL+DouqPp0r4Lb416i3MPOFcVQghEphSA2wC3FSLHAD0TZTQwKUJZlDCpr4cePaCkxPpbX5+fdv3WD6vd5HFjoLTU+uvW3tlnN9WLxaBDh6Y2jzjCem2MVdq3b6qbXlLrJUtpqdVGUs6uXa2SKnP6fZx9tlUn9Zp210ttO/Veu3a17iFZr2PHpmumX//ss8P/jdTXQ9eu/Lub4YBz2nHtG9fyqy2PZNaoWey1zV7u310m14riN14MiEhkBegBvO/w2RTgtJT384HtvNrs3bu3KHmkrk6kokIEmkpFhXU8l+36rR9Wu7W1LY+7tVdba183V6W8XKSsLL8yhPkbqauThvIymdQHaT8e6fpb5NFeWPeYbDes32ZUv/E8A8wSP/22n0qZFg+l8BhwcMr7mUAfrzZVKeSZ6mr7f/rq6ty267d+WO3GYu6dXnp7XvXbYsniN7KiV3c5/lSECcjRg5HlHWzaDeu3GdVvPM/4VQr5dDTbGf/EtqIxo7FMTFRVVUUpk+LFkiXBjkfVrt/jYbW7ebP9cafzvOq3RTL8jTz38XMM/flSVraHa5+Cc9+EktSeItluWL/NqH7jRUKUPgUvlgI7przvDiyzqygiU0Wkj4j06dZNN8HIK05KOVtlHbRdv8eDnF9fb9mQ7YjF7I87tedVvy0S8DeyftN6LnzmQo6ccSRbbSrjrZvg/DfSFEJqu2H9NqP6jRcJ+VQKjwBDE1FIBwLfiMjyPMqj+GHiRKioaH6sosI6nst2/db3W6++HkaPth/hV1RYn6W349be6NH2ddsqAX8j//nyP/S9pS9Xv341tX1qebv3ZPb+qrxlxbKypnbD+m1G9RsvFvzYmDIpwJ3AcmAj1qxgJDAGGJP43AA3AB8B7+HDnyCiPoWCoK7Osq8aY/0NywEXtF2/9f3Uc7Ijl5SIxOPWufG4VVJ9DG7Xra1tqldSIlJZ2SRD//7W6+R12rVz9kOk1kv1cfTv33Rf8bh1DTd7fm1tk/zJazr5T5Jtp95rPG7dQ7Jehw4tn03y/mprM/qNNDQ0yJRZU6T9n9pL/Mq4PPyfh5t/j6nyx+P2gQVh/Daj+o3nEQrB0RxFUaWgRIJdx2tXwo5CCbPzcbuHIujcvlzzpfzirl8IE5Ajbz9Sln27LN8itSr8KoV8mo8UpXDway9euxbGjw/nmkmT1eLFVte9eLH1PtOYeLd7CKP9CJn58Uz2mrwXjy14jKuPupqnBj/Fdh23y7dYbRJVCooC9nZkJ8KKQhk/3lIyqWSjdPzcg1P7eVqstWHzBi569iKOnHEknbboxJtnvskFfS+gxGjXlC8095GiANTUWH/Hj7c6/aoqWL0aVq5sWTesKJSwQx/T70FsI7xbtp+csSQVVHJGkdpmBMz/cj41D9Qwe/lszup9FtccfQ0VZT4VsxIZqo4VJUlNDSxaBA0N1t/rrgsehRJkxO0n9DHoCD71Hqqr/V037BmLByLCze/czH5T9+OTrz/hwV8+yORjJ6tCKBT8OB4KqaijWckpQRzBYafqyDbdgt/znRzUxvi7TgBWrl0pg+4eJExA+k/vL599+1no11DsQaOPFCXHZJIewU3phJFuIZtw3JDTOjz/8fOyw9U7SNllZXLVK1fJ5obNobavuKNKQVGCYteBBpkphD3iztUIPuIEcOs3rZexz44VM8FIr+t7yexls0NpVwmGKgWl7RDUxGNX165jLCuzso367SzDHnHnMjFbJuslfJyz4MsF0mdqH2ECMuqRUbJ6/eqQBVf8okpBaRsEGeW61XXqgIN0ymGPuAs5hbOHbA0NDXLLO7dI5cRK6XJlF3ngwwfyLLCiSkFpGwQZTbvV9bui2ct8E3Z6hHylW/C6rsuzXLV2lZx0z0nCBKTfbf1k6TdLcyOz4ooqBaVtEMTu7lY325lCa8qVYzcLSD675L05PMsXeyA7XrOjlF5WKle8fIVs2rwp33ejJPCrFHSdglLcBElz7FbXbjVwWRmUp2XmdMuwGla6inxjt25BxPqbvLcuXZp9vLEExh8O/YZBu9J2vD7ydX538O+IlWgK8WJDlYJS3ARJc+xWt6YGpk5tWvAVi8HGjdY+xPG4tSdxdbVVJ32Vr9/FX4W872/qftKLF7vXTd5r4lku7AIHj4A/HwIjtjyUd856hz7b94lYYCUy/EwnCqmo+UhpgZfpJvVzr/TXmTh3/ZiwguwpHaUZyulZBC3GSMOMGXJr/7h0GIdsNa5E7pt8briyKqGC+hQURYKHmmYSBurnHD91oo42sms/w7KqZ3c55d5ThAnIYbcdJku+XhKOjEpk+FUKxqpbPPTp00dmzZqVbzGUYqFHD29zSJLqaudEcsZY+YTsSE8oB5ZpJdXUVFLi3a6TrNXVVj6jbAnyLFIxppnsL1dBzcklLO9ouLz/n/jtT36rvoMiwBgzW0Q87XrqU1BaN0Eyji5Z0sKB2ojTcWjuj3DyPTg5uUWa/AtRbxgftJ1YzJJvxgyIx9lYAn/oB4edAVtsaOC1aTD2hL8RKy0rPB+JkjGqFJTWTZA019mkxE7PsJrujHbb68AhoicUubJpJyV99kfbbcFPR8CfDoVhc2HOFNh/yWYrtbi0gogrpRFVCsVOIUe0hEmm9xkk1HTgQPv9EwBWrQoqcXPSo5vSSYvoaSZXWBvGB9lIqLISDjoIEeH2ubezz8+XMT8O99wD0x6GDhtszokw3baSQ/w4HgqpqKM5hUwck8W4yCobB6zTZu/pz6G21t0JG4uF98zcopX8fj+Zfo+p55WUuDqTv9qqvZz6twOFCcghY7aQxVv6cEJHkG5bCQc0+qgNEDRSppBz6biRaWK4IPcbZEVzts8s20R3YX2PLtFIL1ch1ecjsUuQiS9NlE0zbvcXuRRFsj4lFFQptAWCplbOZdbNMAlyn6kj4eQ6BD/3GyT3kV0bQUbutbUtrxekUw9z34a0MNyNJcglhyEllyA7n4u80R37NuLxYBlklbxTEEoBGADMBxYCY20+rwJeAOYA84CBXm2qUkghaOeQwx22QsXvffqNw7e73yAzhWQbqR2q307eScbKSneFktohu8llh5+ZRXW1fNwZ6TsSYQIy7ATk2/IMFY1SkORdKQAx4CNgZ6AcmAvsnlZnKlCbeL07sMirXVUKKQQ1IxTrTMHvffrt2J0S2tldw2nFbzzurYCCZGp1uze/yi4Ws39+Pr73GZPGSMdxyJZjkbv28PFbUoqOQlAKfYGnU96PA8al1ZkC/C6l/mte7apSSCPKPYQLCT/36ccE5LVnst3Oa0GUhdNsIptMrEHOs8Nlhvj191/L6fefLkxADr6ilyzafQcd+bdSCkEpnATcnPJ+CPDPtDrbAe8BS4GvgN4ObY0GZgGzqqqqIntobYLWNOVPvxevjtop8sjrGdjV96OA7GYTfn0XqSYuv+c4zfgclMqr+28jPf7eQ2J/jMnl/7pc01y3cgpBKZxsoxSuT6tzAfCbxOu+wIdAiVu7OlNQRMR/TqP0TjOs2ZLX6N1tNuGnkw86U/CaAaXc88YS5NIjS6VkgpGd/r6TvP7p65l9B0pR4VcpRLl4bSmwY8r77sCytDojgXsAROR1oB3QNUKZlNaCXbrqZKprJ5Ys8Z/m2gu7hWDGWH+TaS6cFryJNKXEiMetxXSppC9Ys7tWebl3Su8kNTUwbBjEYizqDIcOhz8etImavQbz7ph3ObD7gf7vW2n9+NEcmRSgFPgY2IkmR/MeaXWeBM5IvP4hltIwbu3qTEEREecRs5vt3it6Jx7375tJXsMu/XaSIFFTXuasbMx+iZlC/Y+QTmOtckfv8uI2HSqBId/mI0sGBgILsKKQxieOXQYcl3i9O/BqQmG8Cxzl1aYqBcXVpu9lIvLrtA0SUhpG3Qj5ZtcdZfAvrFDTg0Ygn3R2UE5Kq6YglEIURZVCAeK1MCpsp7ZTx56M9vGSye+eAkFDSt02+PGaVbjJnAWvLXlNdjrPWow24VDLn9DseSltBlUKSm5wGg3b5RIKY5RcV+fekYfRRnpHX1vrb+GY0z36mTGEPKvYtHmTXPbiZRL7Y0x6/CYmr+7oU+kprRZVCkpucBo5B0kx4RevUX6QtoOuYA5S0uUIa2c2nyz6apEcPO1gYQJSc3+NfD19akGYsZT84lcpaOpsJTucNm7ZvDlYfT/YRQ4lCZpiOkga6aAsWdI81bfTbmfJZ1Ff713HJ3e9fxd7T96buf+by4xfzKBuUB1bDh3lvQmQoiTQ7TiV7HDa4jEWs1cM2Wwt6bSlJUBdXfBOrr7eUjRLllgKYs2azORKJx6Hb7+1QmTdSD6jtO0um+HzeX23/jvOefIcps+dTt/ufakbVMfOW+0cXHal1aLbcSq5wW7EXVFh7cIV9oYxTjuHVVdnNupN3S2ta8DlMdXVliKyu8d167wVAjQpTSeF4PN5vbn0Tfadsi8z5s3gkkMu4aXhL6lCUDJGlUJbI+yd2pz2J77xxvBNFk4KKIydyYKYaYyxZkfjx1uLwtLvMawZh8fz2tywmYkvTeSgaQexqWET/9p+PH8cPp3S0vLWvQufEi1+HA+FVNTRnAUFEjffQia/IZup9YOEbabvA2C3SM0tb1JlZdPnflJkR+GsTmPx14vlkFsPESYgp913mnw1fUrhfbdKQYFGHyktKLTU2W7RRGF1aF4RS8nwWbecScl6Tooj/fn5yaDqdS2Xe7/7/bul8xWdpcOfO8jt794uDQ0NhffdKgWHKgWlJX432XFKIR32QjSvsNAwOrQoQ0+dZhWVle51ysut5H3p30Hynh2e7Xfrv5PhDw0XJiAH3HSALFy5sOnDfG2g1Jqy7rZyVCkoLfEzmrQbWdt1YmGM5P0sBsuWoNtsRlE6dGhpsgrYmb619C3Z9R+7SskfS+TimRfLhk0bmlfIx0yhEM2RiiOhKAVgkFvxc4GwiyqFLPC5LaPvzi7bDsfPtTLZjD7IHgtBSklJZudl8Zw2bd4kf37pz1J6WalUXVslLy16yfm+c91Bq8mqqAhLKdzqUqb5uUDYRZVClniNUIOMrP2Ynbxk8WPL99uxZbLHQi5KhiacJV8vkUNvPVSYgPzy3l/KV99/5X5CbW3LleSZbiLkh2Ld87uNouYjJTMynSlkOlL1M5L3O/J0kj0ebxl9lEulkMHI+d4P7pWtrthKKidWym1zbrOcyW5k6rTPZoahM4WiInSlAPwMuAi4JFn8nhtmUaUQMZn6FDLtIIJsT+lkj08mrAsyUg+SLTWbUlYWyITz3frvZOQ1hwoTkP1HIf/dc/vsOmiv7yGbjl19CkVFqEoBmAzcDnwKXIq1r/Itfs4Nu6hSSBBl1Ecm0UeZRjYFHbXbKahMR+pBsqVmWsr9b2bz9mdvS8+LtxRzKfL7w5ENJTbtJfeZTsdLuTqZdLI1AWn0UdEQtlKYl/a3A/CMn3PDLqoUpDBHaGFGNoVZvJ5LGKak5D1mOOre3LBZrnj5CimdEJPu/4e8WJ2BosnHTEEpKsJWCm8m/r4BbA9sAfzXz7lhF1UKUpj/yNlENtnZ/MMIJfWzmU08LlJamvk1Uu8xg1H3p998Kv1u6ydMQE4eViGr2gVURG7PP1lKSqLxKShFRdhK4Q9AZ+BE4H/AcuByP+eGXVQpSO6iPjKJJgrDxJQk24VndrJ5neMVdpq64U76PQbcle3+D+9vdCZPe2eaNJiA92e3q5zTwrna2sy/N6VVEFn0UWKWsGXQ88IqqhQkNzOFKEaQQeX2E7LqVOJx93txG/l36OD8udv9+0mpUVcnq9evljMfPlOYgPSZ2kcWfLnA/fn4kTkpl9PmRrFY5t+b0ioIe6ZQkZgt3JR43xM41s+5YRdVChL9lL+uLnc7p0Vl808dGQftbN2u6XX/dmsFUsrs/baVXtf3EjPByNhnx8r6Teubz2IyNZsl5XKro7RpwlYKdyfCUd9PvG8PvOvn3LCLKoUEUU35vUa72ZqogsqdjW8h0xXIXte0ux+P8zYb5KqfIGV/QHa4AHn+gG2aorrSn3dqHqTaWn+KMfm96ExBcSBspTAr8XdOyrG5Ps4bAMwHFgJjHeqcAnwIfADc4dWmKoWIyUWSujDliaJUV/vrXH2apZZ2RPoPRZiAnHgKsrJ94rMgmVe9nkeyfm2t/eduPgWlTRC2UngtMTt4J/F+F+Atj3NiwEfAzkA5MBfYPa1OT2AOsFXi/dZesqhSiBi3UXJYJqpUE0ss1rLDSo8OijJk1ekevZSGMa5momR5cDeky0VIxe+Rm/dFGvzK4TQj82OC83q+SpskNKUAGGAo8C9gBVAPLAIO8zivL/B0yvtxwLi0OlcBZ/oRNFlUKUSM00g0FvMO70yPhEm2ldpBOXWClZVNSiDduVxeHm1qiqQiTA2H9dHhu5XVZcjoY63ZQe/RyPx4wDbcZmTFGi1UrHK3EsKeKcwG4olUF8cCXX2ccxJwc8r7IcA/0+o8lFAMrybWQAzwaleVQsQEcQY71a2tDT+FhJtJx29xW/8Qj4cm8zvbIj/4NWIuRS46plTWd+sSrI2AqTGKAl0PkXfCVgo3APv7qZtyzsk2SuH6tDqPAQ8CZcBOwFKgs01bo4FZwKyqqqoon5si4n9E5zarCFMhQPaL2dzs9yGVzQb5W1/Lmbz9BcjMvTs52/i9lFdroxAXXLYx/CqFEvzRD3jdGPORMWaeMeY9Y8w8j3OWAjumvO8OLLOp87CIbBSRT7Cc0j3TGxKRqSLSR0T6dOvWzafISsbU1MCiRdDQYP112jzeabP7zZvDl6mqCqqr7T+rrnb+DCAWg6lTYdWq8OVKsLwDDBgMFx4Nxy6AeXtP4vDf3gjTpwdvbOVK6NEDSkqsv/X1YYube5x+K07HlfzhR3MA1XbF45xS4GOsGUDS0bxHWp0BwPTE665YCffibu2q+aiAyNVMwRjn8M2kCcJpRF5a2jTTiWim8PAPkPhFSPvxyJTeSEN1lfvz8Zq5pM+KWoOZRWcKeYdC2E8BGAgswIpCGp84dhlwXOK1Aa7BCkl9DzjVq01VCgWEm08hSMfqdz1BLCbSv7+9acup0zGmyYGdrQmqrKyZwltThtT+zHIm73sW8u+uaR242/W81ijY3XsxKwb1KeSdglAKUZQ2rxQKLYLDSR6/o/LkLCBI55wMsUy9dgQzgMa9ldOVVywm726D/PD8MmECcuGJnWRdKc2jl9zSgqdnjk19fm7yBO1Ei+W3ouQEVQqtkWIabfnNN+SVdtpt1BzlJjkOUVSbDXLNgUj5xch2l3eWZz961vl+/WxOlE5YiweL6bei5ARVCq2RXNplwxjVpS6iMsY5RXUynUOQTj4K/0ByrUTyftOusbwDcvRgy1x03KnIil7dm+7VSZ7KSvd1HHbHvdKM+Plu1IavpKFKoTXiZiYJc1ru1DFVVjY3j7jl6A/aaSdH5vlIa5Ha4aYqqZTPHu2FdPut5Uye1CdtZbLXvaY/JzdfjNf9262nsJsB5CK9upqDigpVCq0RN2eqVycRxnXsOnI/HZ7fkuxYovIRZKAg1pYivxpozQ72HoN82DWDttLXHfj9Hu2et99cSVHPFNQ8VXSoUmiNBIlWyeafP0in7LczCtJevhVCoszdBtnjbEshXHAUsi6WRXuZPt9kSfpRguyFHWWnreaposOvUvC7eE0pBGpqrEVY1dVgjPVXxL5uNouCqqr8102/TjbXNQYWL878/JAQ4LoD4MejYGV7eHoGXP0MbBHWmrwgzzdJQ4P1/Tudm37c7rcydarzQsSg6GK0VosqhWIjfbWx00reTDqeJBMnQkWFv7rp1+nSJfPrOim4HPJ5JQysgfOPgaM+gnmTrL9ZEY83fz9xotVRByH5nO2+m4oK63g6flemZ4Jf5aQUHaoUih2nTmLgwMxTJdTUwLBh1rlulJfDl19aHVyyrFwZ9A4Khid6wl618GIPuOFxePhO6LbW58nl5VBZ2fJ4WRlcd13zYzU1wRRgaqcf9QzAL0GUk1Jc+LExFVJp0z4FJ9KjQOzCO93syX7Oh+bRR04bxBdh+b4UOecYy3ew1xjk/W4B2/ATapqOV4qQ5N9CjurR6KOiAnU0t2GCOAEzcV4XSoRQtqWiQt7ruaXsWWsphPOPthREYIWQCRq9o+QYv0pBzUetkSBOwPHjYW2ajUTE/vzFiy1T1ODBznUKnVgMAKmu4vqrTqLP4LWsqIQn6+Dap6HdpoDteTlW6+vtzXipZqCkXGvXWt9Hso7TuYoSJX40RyEVnSn4wGumEHXOoEIutbXy+Q+6y8DTrdnBz67aRz6vzKI9p5mC0wK+9NlAkI2KdCahZAE+ZwrGqls89OnTR2bNmpVvMQqb+noYPbr5DKCiwhqZQsvP7DCmsGcD5eWWfBs3Nh2rqID27V2d3U/tCsNOgG/awd+egV+93x7TviIzB3l5OUyb1tLJa/f8U6mhLKaHAAAcXklEQVSutqKBwJoB2IXhxmL2+1KknqsoATDGzBaRPl711HzUGnGLULEzF6VTUQFjxrhvXJNvNmyATp2scM/Ue3TYSGddKZw/AI4ZDFuvgVlT4ddvgVn7Paxfb0UJBaVjR/uoH69nnGpyCrpRka4DUCJGlUJrId3+DPYx6m6dSmrneuON1nl+4+nr6qySS0WycqVVRGD5chg61HZ280E3OOBMuO5AOPcNePsm2POLlAqrVzefcQS5frqdv77eewFeaiy/U1x/wvfheq6iRIEfG1MhFfUp2BAkkiVoegI/aSfSc/t06JAff0FaaQD55/5Iu/HI1hciT+wawXVSn7PfvE/J/SDcvjv1KSghg4aktiHcOvow1jB4dXTpSiGMzjbLHEhfVCDHnmY5k4+pQf6XqTM5uWtb+r4Ids/Z7zak6d9L+uY8Qdc8KIoPVCm0JdyiiNxSNPvtbJKdk1vHmUqQztZLyaR2jD473ad2Qba5ENniYuQfP05Lcx20JPHaYjRoZlidBSg5xq9SUJ9Ca8DNLp3u8Fy7Fp54wl9OnKSfYvBgWLrU/fqpPo1sZAbLVt+jB5x9tuW0XbzYanfzZlcfx/oYXHA0DBgCXdfC21PhnLesjcCb4ddPknovTzzhXM/uObvh9L2MH++/DUWJCFUKrQGnPDTZRLAkwyqTTlOntsDKfzRihFVXxLvtZI4ch0ghwGpr0qSW13do/8NucMAouLYv/PpNSyH86AvbqlYbqZFZ/fvb1zvrrKbXbs/M7dmkk+33oigRo0qhNeAUgppNBlU/oatJ1qyxQkSdKCmxksWlh8dmE0kTj0M8jgCT+kDv0bCsIzxWD9c/Ce3dViYbYyml5EzpueegtrYp4icWs97feGPTOWFE/cRi2X8vihI1fmxMmRZgADAfWAiMdal3EiBAH6821aeQgpcj0imvUWr0i1O72djh7WzydvIG3Zc5razo1V2OO9VyJg+4ai9Z/t1y/w7qpHM39b2bTT+bHeXSfS9BosXSV0Z7yakoDpBvRzMQAz4CdgbKgbnA7jb1OgIvAW+oUgiAn46lrk6kvLxl5+TmbA6j80vtBFPbtZMlmXk1YNvP7IJs+xuk/GLk2gORzSYEed063Uz2nU4vqWG/fiKL6urso57Ky1UxKIEpBKXQF3g65f04YJxNvb8DxwIvqlIIgJ/8Rm5hlE77Ooe9HWZSHrcO1Sku36asiyG/OcqaHex+NvLuNiHKmv4skgTJJOu3zWy+43QFoyg+8KsUSiO0TO0AfJryfilwQGoFY8y+wI4i8pgx5sIIZWl9eGVCHT/efZWupZCbWLvW2lgniNPUD4sXQ9eu7rmF1q61bO0e1/5PVzj9RJizHZz9Fvz1WajIYCGyJ2vXwnnnWa+T0U/ppD8/N5K+hKAb4bg5ntUprURElI5mu7i/xv8kY0wJcC3wG8+GjBltjJlljJm1YsWKEEUsYry2Q8yk0whbISTxk2zO5doCTOkN+50Fn3aydkS74YmIFEKSlSubIqrc6NDBu63k/spBcXM8q1NaiYgolcJSYMeU992BZSnvOwJ7Ai8aYxYBBwKPGGNaZPETkaki0kdE+nTr1i1CkYsIr+0Qw+w0ysszSxgXAivbw6Bfwpifw8FLrD2Tj5vv40Sn3EEApT4nyG4RVUHqZPpdTJxo/9zLy3XbSyU6/NiYMilAKfAxsBNNjuY9XOq/iPoUguHmrPTyKfjxBSTb7dw5fLu9j/LcTsj2F1jO5Kv7BnAm2zm0U0u2DuNMfAmZpqzQ6CMlJMi3o9mSgYHAAqwopPGJY5cBx9nUVaUQNtmElibZfvvcdaCJsj6G/PZIxFyK7PYrZM62Ac4vKWmKrMqDImtWkmk57HInaVoLJcf4VQq6yU5rx2kTFzficWuVMvhPCREUh0185sctZ/I728OYt+HqZzLwHVRUWE7z6dODpZ8Ii3gcvv/e+9q6YY6SQ3STnbZMah6i1auDnVteDtddF4lYjZSUtPCHCHDzfpYzeXFnePAumPR4hs7kZH6nqVPdfQtOZKsI163zp4wKLYJI94RWUKXQ+kjNWSQSfJvJDRvg1Vetdrp2jUbGhgYrNUaCVe3hpFNg1HHQd6nlTD7hP1leY/FiGDIks4iqbGbPlZXN7s2VqCOIgnTy6b+bxYut96oY2hxqPmptZGIusqO0FDa5JRAKhxd6wJBB8EUl/HkmXPA6lBTXT7IJY6BLF3+KOLlndiahqn5w26fb7ppOvxs1cbUa/JqPVCm0NkpKshvp5ogNMbikH1x1EPRaCXfcD/stz7dUIeDgKwEsX8OqVdYMYeLE6BQCBO/knX43xlgzO6XoUZ9CayZp2jGmqXTtah3P1aKm8vKMT10Qh5+MhCsPhlGzYfaUVqIQqqudn3/See+1h0VYeK14T8drMaTSZlClUGzU18Pw4S1NFCtXWscHDmy5qM2JTJywSfws2kpDgGn7wr5nwSed4YG7YMpjUBnlymQ/ZPMcUhk40HlRYdTO+3SCdvJeiyGVtoOfuNVCKm1+nYJX/H36/r9udTt0yFnM/qp2yEknW4nsDh+KLO2Yo7UCfovXgjc/JTUZYb73Vg6Snjv1nHzLrUQGhbB4LYrS5pWCV0eful9yXV3wbJ5B6/soL1Yj3f8PKf0DcuVBIaa5DqskO8DUlcPl5dZCOLAWoflVoOn7ReSzk9VOXknBr1JQR3Ox4RVdlOpIDBqJFI/Dt9+6Z1cNwMYSuLQfXHEw9Ew4k3sXmu/ALiLHLnKnrMzy3biZzdyczE7XUpQcoY7m1srEic03lE8nmaq6a9fgoakrV4amEBZ2gYNGwl9+CiPfgXemFKBCiMftO2m7rUg3boSOHZu20kxf4OalEMBqc/BgXRimFDSqFAoRr0VHXlk+V64MvmgtJAS4dR/YZ4ylGO67G256tACcyakYY+3B/OWX9qN2pwidVausWZgIzJjRfE/sIDNuXRimFDBqPio0vBYdhbU4LQK+agdjjoV79oTDPoHbH4Qdv823VA64LcrKZCFXJt+LLgxTcoiaj4qF9FnBeee1NF0kdwIrYIXwUjXsXQsP/BD+8hw8d3sBKwRomg3YzcoyCc+0O8evDIpSQKhSyCdnn23l50nNN+Nk9lm5siAVwsYSuPhw6DcMttgEr90CY1+BWKFPQKuqnPP9gDUzSzUPeTmIa2panlNb2+SDcJJBUQoMNR/li/p6SyEU2fNP5aOtoOZEeLM7jHgHrnsKOgRf05Z7kuY4p/2XwzbrBM1DpCgRoOajQmf8+KJVCAJM39tyJs+Pwz33wC2PFIlCAGjf3vrrJxVEGOmk7WYRdmGwmrZaKQB0ppAv3BLXdehgbdKyebOVgqFdO//pmCPm64Qz+e494ZBFUPdAgfsOnHBbd5DMU5SrEb7OJJQcoFlSCx03p3FZWfP1AuXllgJJPVZRYY14cxh6+koV1AyCzzrBZS/A74rBd5AJSaWQq3TSmrZayQFqPip07KJVjLE2aUlfQLZhA3Tq1Nz80LevFTefAzaVWGmuDz0DyhosZ/LvX26lCgGanqubeSlMc4/fjKZqYlJygCqFsAnyj5u0bYM1Op0xw3kbx+TCqYYGKxvnzJk58Ul8vBX8dDhcfigMnQtzJsOPP4v8svklGRXkFB3UpUu4u5T5yWiqO6MpucJPgqRCKgWdEM9vZkq3ek5ZUJMZOEWsBG05SBQ3Yy+k4zhky7HIXXtEf71QS+pzTya281OMaTrP6XtKTZzn9B2F/bvx87tQFBfQLKl5wOkfNxbz/w/up4OIuEP9egvk9EFWmuufDkcWbRnt9UIv6RlBgyiE2trm36ldplGnTLKpGWqD4pXRNIprKm2KglAKwABgPrAQGGvz+QXAh8A8YCZQ7dVmQSsFt7TTqR271z+4VwcR4Uzh1R2RHuchsUuQyw9BNhVamms/HXsqbp14PJ5Zaul8jNp1pqBkSd6VAhADPgJ2BsqBucDuaXX6ARWJ17XA3V7tFrRS8LMBjlu99BmFiL2CqK0NvTPdWIJcehhScgmy03nI690LoIPPpKR3kk7POtVMFJRMNrDJFrtrJhWb7pOg+KAQlEJf4OmU9+OAcS719wVe9Wq3oJWC0z9u+ijWq17SBh6Pi5SVtfy8sjLUjvSTzshPRljmoiG/QL7ZogA690xKWZl/swtk/117zTLC3uQmfSOgXCkkpVVQCErhJODmlPdDgH+61P8ncLFXuwWtFESsf04n807qKNatXg5L/Y+QTmOtcseeBdCxZ1MqK1t+H/kyu0Q1m1AzkpIhfpVClCGpxuaY2FY0ZjDQB/irw+ejjTGzjDGzVqxYEaKIEVBTA9One2fZrKmxwkvzxLdbwJBfWLmLfvQFzJ0Mp72fN3HCYc0aax1HaamVbBDC35Deb8ix3UY9a9dax7PB75oGRckUP5ojk4JP8xFwBPBvYGs/7Rb8TCGJH9OBlw8iovJad8tvELsE+eOhlj8h76P8KEoykigsM06Q0X9U0UI6U1AyhAIwH5UCHwM70eRo3iOtzr5YzuieftstGqXgBy/fQshlk0EuO8RSBj3OsyKN8t5xR1lisXC/ryAdclSddz6c3EqrwK9SiMx8JCKbgF8DTydmAveIyAfGmMuMMcclqv0V6ADca4x51xjzSFTyREY2qQdqamDYsKgka8biLeGwM+CSw+HU9+HdyfCTT3Ny6Whw26c6yebN1t+zz7YSCxpjlQ4dMlsJHMR0E7bZKomfjKuKkg1+NEchlYKaKTiN9Dt0sMwE8XjzSKFkVFHShNG/f05GzHfuaa1K7jgOqftRHkfuYY3+a2ubm4S86jp9FnR0HXT0H3b0kaJkAfk2H0VVCkopZOMTyEHk0bflyNATrFDTviORjztHe73QS3qH72Qmcer4a2vdn3NQU46abpQixq9S0IR42ZBNxEfStBERb+5gbYJTtxdc+iK8dCvs9HWklwwfkebv166FoUNbmupuvNHa+jIWs94nTUSTJ7s/56Dfn5pulDaA7qeQDW57IuSJzQb+8lOYcBh0/xbq74eDitl34IbdRjR2G9Y4ofsVKG0I3U8hF0ycaI0YC4QlW0K/M+APh8MpH1jO5FarEMA+7t9ufYAdsVj2Tl9FaYWoUsiGmhoYM6YgFMM9e8DeY+DdbeH2B6wZQud1+ZYqB6SbgPyYhCorrQWGavZRlBaoUsiWgw6yNl3JE9+Vw/Dj4Zcnw25fWrODIfPsl5O3StI3qHHasKa6usk9vHq1KgRFcUCVQjYk7dc53Cc5lbd2gH3HwO17wx/+ZTmTd/4qL6KES3m5v3p2cf9RrQ9QlDaCKgU/OC1Q82u/DpnNBv78UzhoBGwsgRdvg8tesPZPLnpqa2HaNO96sZi18C99xK8RQoqSFRp95IVdNEsy6mXIkJZhkxHzaScYMgj+1QN++T5MfqyV+Q6Sz9NPZJdd9JGiKLZo9FFYuGW7dLJfR8R9u8NetTB7O7jtQbjzvgJXCPF4S1OOG9XVTa/tzEDphJF1VFGUZqhS8MIpmmXxYvg0N/Geq8th5HFw8inQayXMmQLD5haBM3nVqiZTjhd2qcVTzUBOaMpoRQkVVQpeuM0GcrAfwqztYb+z4NZ9YfxL8Mo02HVV5JcNh6oqq3NftMgyC6WuOi4psUJD3ez+yXMbGpwVS45na4rS2lGl4IUfM0YEbDZwxcHQdySsK7WcyX96voicyWVlzUf+9fXW2oBk2omGBktRzJhhdfxefgGNKlKUnKBKwQ/t2+f0cks7wRFDYdwRMOjfMHcSHFJY2TS86dSpeUef7U5kGlWkKDlBo4/cCJJHJyQe+CGceRxsiMH1T8AZ7xaB78AOY5qb10pK7CO10uspihIJGn0UBjlch7CmDEb9HE78JeyyCuZMhuHFqhDA/0pj9QkoSkHRNpRCJruj1dfnLAPq7O0sZ/It+8G4l+G1W6BnsTiT7dCVxopStLR+pZA0AS1ebJkvFi+23rsphvp6GDEictEaDFx1EPQ9E9aUw/PT4c8zi8iZnEoyqsgtkihKn0A226IqitJI6/cpOK2Mdculn4N9Ej7rCMN+ATN3hhM/hKmPQpfvI71kZhjjvWo73/sSuK06V0e0ogDqU2giyGbrSSJWCA/tZq1Mfr073Pww3HtPgSoEsNYSlJW51xk4ML8j9WwjmxRFaaT1K4WgDs76+sj2R1hTBmcdC7841doac84UGDmnwJ3Jq1dbzyMed65z000wfHgwE12YZKL4FUWxJVKlYIwZYIyZb4xZaIwZa/P5FsaYuxOfv2mM6RG6EEEdnOPHR5Lkbs620PssuKk3XPSK5UzulZ+M28HZsMHa89hpVfGmTbBxY/NjuRypa2STooRGZErBGBMDbgCOAXYHTjPG7J5WbSTwlYjsClwLXBm6IEEdnCGPLhsMXN0XDhhlbYjz3O1w5XNQ7rKffEGyZEnwZ5OrkbpGNilKaEQ5U/gxsFBEPhaRDcBdwPFpdY4Hpide3wf0NyYC201qDh2vlAohji6XdYQBg+HCo+HYBTBvEhz+SWjN55aqquDPJlcjdV3trCihEaVS2AFITSO6NHHMto6IbAK+AVyM1zkgpFxHr1RZzuRXd4Spj8D9d0M8387k1C0pRaCuruW9lpW13PksOeqeONHe6Vxa2vJ4rkfqQRS/oiiORKkU7Eb86cZ6P3Uwxow2xswyxsxasWJFKMI5kjrqhOZZPQOw81fQexm8MwVGvVMgzuR0c47dCPvWW62dz+xG3TU11uepTud4HG67zTquI3VFKXoiW6dgjOkLTBCRoxPvxwGIyF9S6jydqPO6MaYU+B/QTVyEyvnOa6nU11tbQG52cAgYY42Q16yx3nfoAN9/71w/1+R7PYGiKHmjENYpvA30NMbsZIwpB04FHkmr8wgwLPH6JOB5N4WQd2pqrPTPdhvLl5VZaaBXr24yz3z3nRWZ42Wyqaiw9hrw2rC+rMw6364NL9TxqiiKH0QksgIMBBYAHwHjE8cuA45LvG4H3AssBN4CdvZqs3fv3pJ36upE4vGmrj4et44FOb+6WsQY62/y3PR2U0v6NdLbqK11fx9EPkVRWh3ALPHRb7f+NBeKoihKQZiPFEVRlCJDlYKiKIrSiCoFRVEUpRFVCoqiKEojqhQURVGURoou+sgYswJYA3yZb1l80JXikBNU1igoFjmheGQtFjmh8GStFpFuXpWKTikAGGNm+QmtyjfFIieorFFQLHJC8chaLHJCccmaipqPFEVRlEZUKSiKoiiNFKtSmJpvAXxSLHKCyhoFxSInFI+sxSInFJesjRSlT0FRFEWJhmKdKSiKoigRUBRKwRjTxRjzrDHmv4m/W9nU2ccY87ox5gNjzDxjzC9zKN8AY8x8Y8xCY8xYm8+3MMbcnfj8TWNMj1zJZiOLl6wXGGM+TDzDmcaY6kKUM6XeScYYMcbkLcrDj6zGmFMSz/UDY8wduZYxIYPXd19ljHnBGDMn8f0PzJOc04wxXxhj3nf43Bhj/pG4j3nGmP1yLWOKLF6y1iRknGeMec0Ys3euZQyMn1Sq+S7AVcDYxOuxwJU2dXoBPROvtweWA51zIFsMKzX4zkA5MBfYPa3O2cDkxOtTgbvz9Bz9yNoPqEi8rs2HrH7kTNTrCLwEvAH0KeBn2hOYA2yVeL91gco5FahNvN4dWJSnZ3oIsB/wvsPnA4EnsTY0PBB4Mx9y+pT1Jynf+zH5lNVvKYqZAnA8MD3xejpwQnoFEVkgIv9NvF4GfAF4LtQIgR8DC0XkYxHZANyVkDeVVPnvA/obY/KxQ6enrCLygoisTbx9A+ieYxnB3zMFuBxrwLAul8Kl4UfWUcANIvIVgIh8kWMZwZ+cAnRKvN4SWJZD+ZqEEHkJWOVS5XjgdrF4A+hsjNkuN9I1x0tWEXkt+b2Tv/+nQBSLUthGRJYDJP5u7VbZGPNjrNHQRzmQbQfg05T3SxPHbOuIyCbgGyBO7vEjayojsUZkucZTTmPMvsCOIvJYLgWzwc8z7QX0Msa8aox5wxgzIGfSNeFHzgnAYGPMUuAJ4JzciBaYoL/jQiFf/0+BKM23AEmMMc8B29p8ND5gO9sBM4BhItIQhmxel7Q5lh7S5adOLvAthzFmMNAHODRSiexxldMYUwJcC5yRK4Fc8PNMS7FMSIdhjRRfNsbsKSJfRyxbKn7kPA24TUSuTuyxPiMhZy7+j4JQKP9PvjHG9MNSCgfnWxYvCkYpiMgRTp8ZYz43xmwnIssTnb7t9NsY0wl4HLg4Ma3MBUuBHVPed6fltDtZZ6kxphRrau42PY4KP7JijDkCSxkfKiLrcyRbKl5ydgT2BF5MWOG2BR4xxhwnIrnels/v9/+GiGwEPjHGzMdSEm/nRsRGGbzkHAkMABCR140x7bDy9+TD3OWGr99xoWCM2Qu4GThGRFbmWx4visV89AgwLPF6GPBwegVjTDnwIJat8d4cyvY20NMYs1NChlOx5E0lVf6TgOcl4XnKMZ6yJswyU7D20c5XZ+Aqp4h8IyJdRaSHiPTAstXmQyF4yprgISwHPsaYrljmpI9zKqU/OZcA/QGMMT/E2kN9RU6l9McjwNBEFNKBwDdJ83KhYYypAh4AhojIgnzL44t8e7r9FCz7+0zgv4m/XRLH+wA3J14PBjYC76aUfXIk30BgAZYPY3zi2GVYHRVY/1z3AguBt4Cd8/gsvWR9Dvg85Rk+UohyptV9kTxFH/l8pga4BvgQeA84tUDl3B14FSsy6V3gqDzJeSdW9OBGrFnBSGAMMCbled6QuI/38vzde8l6M/BVyv/TrHzJ6rfoimZFURSlkWIxHymKoig5QJWCoiiK0ogqBUVRFKURVQqKoihKI6oUFEVRlEZUKShKlhhjVif+bm+Muc+j7vnGmIqA7R9mjMl3Og+ljaBKQVFsMMbEgp4jIstE5CSPaucDgZSCouQSVQpKm8MY08MY8x9jzPREnvv7jDEVxphFxphLjDGvACcbY3YxxjxljJltjHnZGLNb4vydjLV3x9vGmMvT2n0/8TpmjPmbMea9xDXOMcaci5XW/QVjzAuJekcl2nrHGHOvMaZD4viAhIyvAINy/YyUtosqBaWt8gNgqojsBXyLtecFwDoROVhE7sLaX+AcEekNXAjcmKhzHTBJRPYH/ufQ/mhgJ2DfxDXqReQfWDl6+olIv0TKi4uBI0RkP2AWcEEi59BNwM+Bn2KfKFJRIqFgEuIpSo75VEReTbyuA85NvL4bIDFi/wlwb8rWF1sk/h4EnJh4PQO40qb9I7A2VtoEICJ2CRAPJJFaInGNcuB1YDfgE0nsD2KMqcNSMooSOaoUlLZKen6X5Ps1ib8lwNciso/P89MxPus8KyKnNTtozD4+zlWUSFDzkdJWqUrsGQDWPgKvpH4oIt9ipbk+GRr3BU7ur/sqVpZRgBqH9p8BxiRSpWOM6ZI4/h1W6m+wsrseZIzZNVGnwhjTC/gPsJMxZpcU+RQlJ6hSUNoq/waGGWPmAV2ASTZ1aoCRxpi5wAc0bV95HvArY8zbWHtj2HEzVirqeYnzT08cnwo8aYx5QURWYG0UdGdCjjeA3URkHZa56PGEo3lxdreqKP7RLKlKm8MY0wN4TET2zLMoilJw6ExBURRFaURnCoqiKEojOlNQFEVRGlGloCiKojSiSkFRFEVpRJWCoiiK0ogqBUVRFKURVQqKoihKI/8PsIix1N4vJjwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot outputs predicted vs real value \n",
    "%matplotlib inline\n",
    "pl.plot(p, targetY,'ro')\n",
    "pl.plot([0,1.3],[0,1.3], 'g-')\n",
    "pl.xlabel('predicted')\n",
    "pl.ylabel('real')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Simple Linear Regression\n",
      "RMSE on training: 0.1289\n",
      "RMSE on 10-fold CV: 0.1359\n"
     ]
    }
   ],
   "source": [
    "#Finally, perform 10-fold cross- validation and compare the cross-validation \n",
    "#RMSE to the training RMSE (for cross validation, you should use the \n",
    "#KFoldmodule from sklearn.cross_validation).\n",
    "# Now let's compute RMSE using 10-fold x-validation\n",
    "n = 10\n",
    "kf = KFold(len(x), n_folds=n)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    linreg.fit(x[train],targetY[train])\n",
    "    p = linreg.predict(x[test])\n",
    "    e = p-targetY[test]\n",
    "    xval_err += np.sqrt(np.dot(e,e)/len(x[test]))\n",
    "       \n",
    "rmse_10cv = xval_err/n\n",
    "\n",
    "\n",
    "method_name = 'Simple Linear Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5497462154012411\n",
      "6 0.6094624178069088\n",
      "11 0.6188591701442955\n",
      "16 0.6234219314963412\n",
      "21 0.6341268202083287\n",
      "26 0.6491115775710352\n",
      "31 0.6518299912475541\n",
      "36 0.6525499626379327\n",
      "41 0.6532826916764793\n",
      "46 0.6517898644360777\n",
      "51 0.650180868861667\n",
      "56 0.652239004867672\n",
      "61 0.6532579587547073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 0.6540008668740999\n",
      "71 0.6529207201190572\n",
      "76 0.6578787053126556\n",
      "81 0.6573210580404087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 0.657800840577771\n",
      "91 0.6574528507097727\n",
      "96 0.6580999906856861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-408-255693796d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0moptimal_percentile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimal percentile of features:{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimal_percentile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0moptimal_num_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimal_percentile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimal number of features:{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_num_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "#1C\n",
    "#data set names / x and targetY\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, targetY, test_size = 0.2, random_state = 33)\n",
    "\n",
    "from sklearn import feature_selection\n",
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "percentiles = range(1, 100, 5)\n",
    "results = []\n",
    "for i in range(1, 100, 5):\n",
    "    fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=i)\n",
    "    X_train_fs = fs.fit_transform(x_train, y_train)\n",
    "    scores = abs(cross_validation.cross_val_score(linreg, X_train_fs, y_train, cv=5))\n",
    "    print (i,scores.mean())\n",
    "    results = np.append(results, scores.mean())\n",
    "\n",
    "optimal_percentile = np.where(results == results.max())[0]\n",
    "print (\"Optimal percentile of features:{0}\".format(percentiles[optimal_percentile]), \"\\n\")\n",
    "optimal_num_features = int(percentiles[optimal_percentile]*len(x.columns)/100)\n",
    "print (\"Optimal number of features:{0}\".format(optimal_num_features), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1d run ridge and lasso reggression \n",
    "\n",
    "# Create linear regression object with a ridge coefficient 0.5\n",
    "ridge = Ridge(fit_intercept=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create testing and training data split. \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, targetY, test_size = 0.2, random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training set\n",
    "ridge.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Ridge Regression\n",
      "RMSE on training: 0.1302\n",
      "RMSE on 10-fold CV: 0.1290\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE on training data\n",
    "p = ridge.predict(x)\n",
    "err = p-targetY #target y is our predictor variable \n",
    "total_error = np.dot(err,err)\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "# Compute RMSE using 5-fold x-validation\n",
    "\n",
    "n = 5 #use 5 for K folds as required by HW\n",
    "kf = KFold(len(x), n_folds=n)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    ridge.fit(x[train],targetY[train])\n",
    "    p = linreg.predict(x[test])\n",
    "    e = p-targetY[test]\n",
    "    xval_err += np.sqrt(np.dot(e,e)/len(x[test]))\n",
    "rmse_10cv = xval_err/n\n",
    "\n",
    "\n",
    "method_name = 'Ridge Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression\n",
      "alpha\t RMSE_train\t RMSE_10cv\n",
      "\n",
      "0.010\t 0.1298\t\t 0.2715\n",
      "0.418\t 0.1303\t\t 0.2701\n",
      "0.826\t 0.1306\t\t 0.2700\n",
      "1.234\t 0.1309\t\t 0.2700\n",
      "1.642\t 0.1312\t\t 0.2701\n",
      "2.050\t 0.1314\t\t 0.2702\n",
      "2.458\t 0.1316\t\t 0.2703\n",
      "2.866\t 0.1318\t\t 0.2704\n",
      "3.274\t 0.1320\t\t 0.2705\n",
      "3.682\t 0.1321\t\t 0.2706\n",
      "4.090\t 0.1323\t\t 0.2707\n",
      "4.498\t 0.1324\t\t 0.2708\n",
      "4.906\t 0.1326\t\t 0.2709\n",
      "5.313\t 0.1327\t\t 0.2710\n",
      "5.721\t 0.1328\t\t 0.2711\n",
      "6.129\t 0.1329\t\t 0.2712\n",
      "6.537\t 0.1330\t\t 0.2713\n",
      "6.945\t 0.1331\t\t 0.2714\n",
      "7.353\t 0.1332\t\t 0.2715\n",
      "7.761\t 0.1333\t\t 0.2716\n",
      "8.169\t 0.1333\t\t 0.2716\n",
      "8.577\t 0.1334\t\t 0.2717\n",
      "8.985\t 0.1335\t\t 0.2718\n",
      "9.393\t 0.1336\t\t 0.2719\n",
      "9.801\t 0.1337\t\t 0.2719\n",
      "10.209\t 0.1337\t\t 0.2720\n",
      "10.617\t 0.1338\t\t 0.2721\n",
      "11.025\t 0.1339\t\t 0.2722\n",
      "11.433\t 0.1339\t\t 0.2722\n",
      "11.841\t 0.1340\t\t 0.2723\n",
      "12.249\t 0.1340\t\t 0.2723\n",
      "12.657\t 0.1341\t\t 0.2724\n",
      "13.065\t 0.1341\t\t 0.2725\n",
      "13.473\t 0.1342\t\t 0.2725\n",
      "13.881\t 0.1343\t\t 0.2726\n",
      "14.289\t 0.1343\t\t 0.2726\n",
      "14.697\t 0.1344\t\t 0.2727\n",
      "15.104\t 0.1344\t\t 0.2728\n",
      "15.512\t 0.1345\t\t 0.2728\n",
      "15.920\t 0.1345\t\t 0.2729\n",
      "16.328\t 0.1346\t\t 0.2729\n",
      "16.736\t 0.1346\t\t 0.2730\n",
      "17.144\t 0.1346\t\t 0.2730\n",
      "17.552\t 0.1347\t\t 0.2731\n",
      "17.960\t 0.1347\t\t 0.2731\n",
      "18.368\t 0.1348\t\t 0.2732\n",
      "18.776\t 0.1348\t\t 0.2732\n",
      "19.184\t 0.1349\t\t 0.2733\n",
      "19.592\t 0.1349\t\t 0.2733\n",
      "20.000\t 0.1349\t\t 0.2734\n"
     ]
    }
   ],
   "source": [
    "print('Ridge Regression')\n",
    "print('alpha\\t RMSE_train\\t RMSE_10cv\\n')\n",
    "alpha = np.linspace(.01,20,50)\n",
    "t_rmse = np.array([])\n",
    "cv_rmse = np.array([])\n",
    "\n",
    "for a in alpha:\n",
    "    ridge = Ridge(alpha=a)\n",
    "    \n",
    "    # computing the RMSE on training data\n",
    "    ridge.fit(x_train,y_train)\n",
    "    p = ridge.predict(x)\n",
    "    err = p-targetY\n",
    "    total_error = np.dot(err,err)\n",
    "    rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "    # computing RMSE using 10-fold cross validation\n",
    "    kf = KFold(len(x), n_folds=10)\n",
    "    xval_err = 0\n",
    "    for train, test in kf:\n",
    "        ridge.fit(x[train], targetY[train])\n",
    "        p = ridge.predict(x[test])\n",
    "        err = p - targetY[test]\n",
    "        xval_err += np.sqrt(np.dot(err,err)/len(x[test]))\n",
    "    rmse_10cv = xval_err/n\n",
    "    \n",
    "    t_rmse = np.append(t_rmse, [rmse_train])\n",
    "    cv_rmse = np.append(cv_rmse, [rmse_10cv])\n",
    "    print('{:.3f}\\t {:.4f}\\t\\t {:.4f}'.format(a,rmse_train,rmse_10cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XuYHXWd5/H355zTnQ4hIsRwzRVFJQQIpGG8BVyuwVEyjqjJ6sjt2ThAvCC6G1eYCzPPPiuRHR/HuIKuDvrMGLk4go5AMiwjuhqlgQQISSBgIA0oMdyMIX397h9V56T69Omu7qSrm5DP63nqOVW/S9W3q0//vl1V51QpIjAzMxtMaawDMDOzVz8nCzMzy+VkYWZmuZwszMwsl5OFmZnlcrIwM7NchSYLSfMlbZS0SdLSBvWfkfSIpAcl3SVpeqbuGknrJK2X9BVJKjJWMzMbWGHJQlIZWA6cA8wCFkmaVdfsAaA1Io4DbgauSfu+A3gncBwwGzgJOLWoWM3MbHBFHlmcDGyKiCciohNYASzINoiIuyNiR7q4GphSrQJagGZgHNAE/K7AWM3MbBCVAtd9BLAls9wO/Mkg7S8GbgeIiF9Kuht4FhDw1YhYP9jG3vCGN8SMGTP2KGAzs33Nfffd9/uImJzXrshk0egaQ8N7i0j6KNBKeqpJ0puAo9l1pLFK0ikRcU9dv8XAYoBp06bR1tY2QqGbme0bJD05lHZFnoZqB6ZmlqcAz9Q3knQG8AXg3IjoSIvfD6yOiO0RsZ3kiONt9X0j4vqIaI2I1smTcxOjmZntpiKTxb3AUZJmSmoGFgK3ZRtIOgG4jiRRPJepego4VVJFUhPJEcegp6HMzKw4hSWLiOgGlgB3kgz0N0bEOklXSzo3bbYM2B+4SdIaSdVkcjPwOPAQsBZYGxE/KipWMzMbnF4rtyhvbW0NX7MwMxseSfdFRGteO3+D28zMcjlZmJlZLicLMzPLVeT3LMzM9h69vRA90NtT99oL0aguLa+WZefr11Wry7z2qY8G6662r99+b99tRC9MPAxaLyx09zhZmL1WVAec3u50MOlOl3vqlrsblNUt1+Z7+/etDni17VQHtW76D7T185n+g5X1WW+jbTUa0Aca6AdYZ/0AvzebcpKTxajo3AHN+411FDYSsgNmb1fy2tO9a7mnq399b09a3t1/Gqh9n3Y9mbaD1NeXRc8AbbKD6BDaVNtF71jv/YGpDKUylCrpfCl9rSTluWXlvq+V5gblpf7t8sob1jXa5gBtVaprXxpku6W+629Y32g7Dcr7tBmdqwlOFjtfgmvfClNa4S3vgTfPh4NmjnVUY6M60PZ0JlNv9675nnS+OuD2dKavXXXlDZb7zXc3rq+v6zMAN6jL1mfbjZVSZdekMpSry027Bsp+r5mp0gLlpr4D5kB9aoNvfVklGTz6LNcNfLV4yvQfnOsH9YHalfq26de2LjHYXs/Joqcb/uTjsPF2uGNpMh08C95yTpI8Jr8FyuPSP+LdfKRGb29mwKsbZGuDZGemLDPf3VFXnqnv7qjr19F3vfXr6umE7gZl2fnGt+8aGSolA1W5KRlIyk1Qbt41X2pKB9imXcvN++0acOvrSuX+/WrrqvSfH3C5vGsb1cG0XOnbrjbI1vVRGoNKu//+MNsL+Et5Wc8/ARvvgI0/gSd/UXceU1AZlySOyrhkoIheIJL/yGvzvfQ77VDY6YFMTOWmXYNvuTktrw7GTclhe7m5b5tyU9o3W54ZjKs/Z619pUF5pn2/5br5Urmg/WBmu2uoX8rzkUXWQUfC2y9NpldegE13wcvPJP+xd3dC9870v/OdSRJQCVDmv8p0vlSpOwWR/mdaHUyzA+1AA3m/8rpBvTLOg6+ZjRoni4GMPxCOPW+sozAze1XwlSczM8vlZGFmZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVmuQpOFpPmSNkraJGlpg/rPSHpE0oOS7pI0PVM3TdJKSevTNjOKjNXMzAZWWLKQVAaWA+cAs4BFkmbVNXsAaI2I44CbgWsydd8BlkXE0cDJwHNFxWpmZoMr8sjiZGBTRDwREZ3ACmBBtkFE3B0RO9LF1cAUgDSpVCJiVdpue6admZmNsiKTxRHAlsxye1o2kIuB29P5NwMvSvqBpAckLUuPVMzMbAwUmSwa3dy/4f3QJX0UaAWWpUUVYB7wWeAk4Ejgggb9Fktqk9S2devWkYjZzMwaKDJZtANTM8tTgGfqG0k6A/gCcG5EdGT6PpCewuoGfgicWN83Iq6PiNaIaJ08efKI/wBmZpYoMlncCxwlaaakZmAhcFu2gaQTgOtIEsVzdX0PlFTNAKcBjxQYq5mZDaKwZJEeESwB7gTWAzdGxDpJV0s6N222DNgfuEnSGkm3pX17SE5B3SXpIZJTWt8oKlYzMxucH6tqZrYPG+pjVf0NbjMzy+VkYWZmuZwszMwsl5OFmZnlcrIwM7NcThZmZpbLycLMzHI5WZiZWS4nCzMzy+VkYWZmuZwszMwsl5OFmZnlcrIwM7NcThZmZpbLycLMzHI5WZiZWS4nCzMzy+VkYWZmuZwszMwsV6HJQtJ8SRslbZK0tEH9ZyQ9IulBSXdJml5X/zpJT0v6apFxmpnZ4ApLFpLKwHLgHGAWsEjSrLpmDwCtEXEccDNwTV393wE/LSpGMzMbmiKPLE4GNkXEExHRCawAFmQbRMTdEbEjXVwNTKnWSZoLHAKsLDBGMzMbgiKTxRHAlsxye1o2kIuB2wEklYBrgc8NtgFJiyW1SWrbunXrHoZrZmYDKTJZqEFZNGwofRRoBZalRZcCP4mILY3a11YWcX1EtEZE6+TJk/coWDMzG1ilwHW3A1Mzy1OAZ+obSToD+AJwakR0pMVvB+ZJuhTYH2iWtD0i+l0kNzOz4hWZLO4FjpI0E3gaWAj852wDSScA1wHzI+K5anlEfCTT5gKSi+BOFGZmY6Sw01AR0Q0sAe4E1gM3RsQ6SVdLOjdttozkyOEmSWsk3VZUPGZmtvsU0fAywl6ntbU12traxjoMM7O9iqT7IqI1r52/wW1mZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVkuJwszM8vlZGFmZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVkuJwszM8vlZGFmZrmcLMzMLFehyULSfEkbJW2StLRB/WckPSLpQUl3SZqels+R9EtJ69K6DxcZp5mZDa6wZCGpDCwHzgFmAYskzapr9gDQGhHHATcD16TlO4CPRcQxwHzgy5JeX1SsZmY2uCKPLE4GNkXEExHRCawAFmQbRMTdEbEjXVwNTEnLH42Ix9L5Z4DngMkFxmpmZoMoMlkcAWzJLLenZQO5GLi9vlDSyUAz8PiIRmdmZkNWKXDdalAWDRtKHwVagVPryg8DvgucHxG9DfotBhYDTJs2bU/jNTOzARR5ZNEOTM0sTwGeqW8k6QzgC8C5EdGRKX8d8G/AlRGxutEGIuL6iGiNiNbJk32WysysKEUmi3uBoyTNlNQMLARuyzaQdAJwHUmieC5T3gz8K/CdiLipwBjNzGwICksWEdENLAHuBNYDN0bEOklXSzo3bbYM2B+4SdIaSdVk8iHgFOCCtHyNpDlFxWpmZoNTRMPLCHud1tbWaGtrG+swzMz2KpLui4jWvHb+BreZmeVysjAzs1xOFmZmlqvI71mYmQ2oq6uL9vZ2du7cOdah7BNaWlqYMmUKTU1Nu9XfycLMxkR7ezsTJ05kxowZSI2+w2sjJSLYtm0b7e3tzJw5c7fW4dNQZjYmdu7cyaRJk5woRoEkJk2atEdHcU4WZjZmnChGz57uaycLM9tnlctl5syZw+zZs3nf+97Hiy++CMDmzZuRxFVXXVVr+/vf/56mpiaWLFkCwMaNG3n3u9/NnDlzOProo1m8eDEA//Ef/8EBBxzAnDlzatO///u/99nut7/97Vpdc3Mzxx57LHPmzGHp0n6P/RnQli1b+PCHR/FRPxEx4ASclpmfWVf354P1He1p7ty5YWZ7j0ceeWSsQ4gJEybU5j/2sY/F3//930dExG9+85s48sgjY86cObX6r33ta3H88cfHZZddFhERZ511Vvzwhz+s1T/44IMREXH33XfHn/7pnw45hunTp8fWrVsb1nV1dQ39hxmCRvscaIshjLF5RxZfyszfUld35UglLDOzsfb2t7+dp59+urY8fvx4jj76aKp3hvj+97/Phz70oVr9s88+y5QpU2rLxx577IjEceWVV/Lxj3+cM888kwsvvJDHH3+cefPmccIJJzB37lx+9atfAbBp0ybmzEnugvTNb36T8847j7PPPpujjjqKz3/+8yMSS1bep6E0wHyjZTOzvVJPTw933XUXF198cZ/yhQsXsmLFCg499FDK5TKHH344zzyT3Dz78ssv57TTTuMd73gHZ511FhdeeCGvf33yQM+f/exntYEc4JZbbuGNb3zjkON54IEHuOeee2hpaWHHjh2sWrWKlpYWNmzYwPnnn19LGFlr167l/vvvp1Kp8OY3v5lPfOITHH744buzOxrKSxYxwHyjZTOz3fK3P1rHI8+8PKLrnHX46/jr9x0zaJtXXnmFOXPmsHnzZubOncuZZ57Zp37+/PlcddVVHHLIIf2uD1x44YWcffbZ3HHHHdx6661cd911rF27FoB58+bx4x//eLdjX7BgAS0tLQB0dHSwZMkS1q5dS6VS4fHHGz8H7owzzmDixIkAvPWtb+Wpp54a0WSRdxrqSEm3SfpRZr66vHsf1jUze5UYP348a9as4cknn6Szs5Ply5f3qW9ubmbu3Llce+21fOADH+jX//DDD+eiiy7i1ltvpVKp8PDDDw+4reXLl9cualePTgYyYcKE2vy1117L1KlTeeihh/j1r39NR0dHwz7jxo2rzZfLZbq7uwfdxnDlHVlkn5n9pbq6+mUzs92SdwRQtAMOOICvfOUrLFiwgEsuuaRP3RVXXMGpp57KpEmT+pTfcccdnH766TQ1NfHb3/6Wbdu2ccQRR7Bhw4aG27jsssu47LLLhh3bSy+9xJve9CYkccMNN1Q/YDTqBk0WEfHT7LKkJmA28HRkHlZkZra3O+GEEzj++ONZsWIF8+bNq5Ufc8wxHHNM/2S2cuVKPvWpT9VOFy1btoxDDz2UDRs29LtmceWVV3LeeeftVlxLlizhvPPO43vf+x5nnHFGnyOI0TTo8ywkfR34x0geWnQA8EugBzgI+GxEfG90wszn51mY7V3Wr1/P0UcfPdZh7FMa7fORep7FvIhYl85fCDwaEccCc4H/ujvBmpnZ3icvWXRm5s8EfggQEb8tLCIzM3vVyUsWL0p6r6QTgHcCdwBIqgDjiw7OzMxeHfKSxceBJcC3gU9njihOB/4tb+WS5kvaKGmTpH43PZH0GUmPSHpQ0l2Spmfqzpf0WDqdP/QfyczMRlrep6EeBeY3KL8TuHOwvpLKwHKS01ftwL2SbouIRzLNHgBaI2KHpEuAa4APSzoI+GugleTLf/elfV8Y+o9mZmYjZdBkIekrg9VHxCcHqT4Z2BQRT6TrWkHyvY1asoiIuzPtVwMfTefPBlZFxPNp31UkSetV8+krM7N9Sd6X8v4SeBi4EXiG4d0P6ghgS2a5HfiTQdpfDNw+SN8j6jtIWgwsBpg2bdowQjMzs+HIu2ZxGHA9yX/6fwE0AbdFxA0RcUNO30aJpeGXOiR9lOSU07Lh9I2I6yOiNSJaJ0+enBOOmVlfY/U8i6otW7Ywc+ZMnn/+eQBeeOEFZs6cyZNPPsnMmTPZuHFjn/af/vSnueaaawb8eTZv3szs2bN3f4cMYtBkERHbIuLrEfGfgAuA1wPrJP3FENbdDkzNLE8hOTrpQ9IZwBeAcyOiYzh9zcz2RPXeUA8//DAHHXRQn3tDHXnkkX1uBnjTTTf1+Sb3Jz/5SS6//HLWrFnD+vXr+cQnPlGrmzdvHmvWrKlNZ5xxRsPtT506lUsuuaT20KOlS5eyePFipk+fXrvjbVVvby8333zz6D7wKGNIT8qTdCLwaZJrCrcD9w2h273AUZJmSmoGFgK31a33BOA6kkSRvX3IncBZkg6UdCBwFjkX1M3M9sRYPc/i8ssvZ/Xq1Xz5y1/m5z//OVdccQUAixYt6pMs7rnnHmbMmMH06dPZvHkz8+bN48QTT+TEE0/kF7/4xW5tezjyLnD/LfBeYD2wAvh8RAzpVoYR0S1pCckgXwa+ld425GqSJzPdRnLaaX/gpvT5sE9FxLkR8bykvyNJOABXVy92m9lr0O1L4bcPjew6Dz0WzvmfQ2o6ls+zaGpqYtmyZcyfP5+VK1fS3NwMwHHHHUepVGLt2rW1e1YtWrQIgIMPPrj2jIvHHnuMRYsWUfTtjvIucF8FPAEcn07/Ix3UBUREHDdY54j4CfCTurK/ysw3PjZL6r4FfCsnPjOz3fZqeZ7F7bffzmGHHcbDDz/cJ4bq0cUxxxzDrbfeytVXXw1AV1cXS5YsYc2aNZTLZR599NHd3QVDlpcs/MwKMyveEI8ARlr1msVLL73Ee9/7XpYvX84nP7nrGwHZ51msW7eOH/3oR336V59ncdFFFzF79uxBn2cxkDVr1rBq1SpWr17Nu971LhYuXMhhhx0GJMnirLPO4tRTT+W4447j4IMPBuAf/uEfOOSQQ1i7di29vb21O98WKe8C95ONJpIL0O8qPDozs1FQfZ7Fl770Jbq6uvrUXXHFFXzxi19s+DyLatvs8yyGIyK45JJL+PKXv8y0adP43Oc+x2c/+9la/Rvf+EYmTZrE0qVLa6egIHnGxWGHHUapVOK73/0uPT09w/2Rh23QZCHpdZI+L+mrks5S4hMkp6Y+NFhfM7O9SfZ5FlnHHHMM55/f/45DK1euZPbs2Rx//PGcffbZtedZwK5rFtXp5ptvbrjNb3zjG0ybNq126unSSy9lw4YN/PSnux4ltGjRIjZs2MD73//+Wtmll17KDTfcwNve9jYeffTRPk/WK0re8yxuBV4geY7F6cCBQDPwqYhYU3h0w+DnWZjtXfw8i9G3J8+zyLtmcWT6/AokfRP4PTAtIv6wu8GamdneJy9Z1E7eRUSPpN84UZiZDc+2bds4/fTT+5Xfdddd/a6FvFrlJYvjJb2czgsYny5XPzr7ukKjMzN7DZg0aRJr1ryqztwPW94tysujFYiZ7XsigvS7W1awwa5PD8WQbvdhZjbSWlpa2LZt2x4PYpYvIti2bdsefR8j7zSUmVkhpkyZQnt7O1u3bh3rUPYJLS0tfe5lNVxOFmY2Jpqampg50zeJ2Fv4NJSZmeVysjAzs1xOFmZmlsvJwszMcjlZmJlZLicLMzPL5WRhZma5Ck0WkuZL2ihpk6SlDepPkXS/pG5J59XVXSNpnaT1kr4i3xPAzGzMFJYsJJWB5cA5wCxgkaRZdc2eAi4A/qWu7zuAdwLHAbOBk4BTi4rVzMwGV+Q3uE8GNkXEEwCSVgALgEeqDSJic1rXW9c3gBaSBy0JaAJ+V2CsZmY2iCJPQx0BbMkst6dluSLil8DdwLPpdGdErB/xCM3MbEiKTBaNrjEM6faSkt4EHA1MIUkwp0k6pUG7xZLaJLX5ZmRmZsUpMlm0A1Mzy1OAZ4bY9/3A6ojYHhHbgduBt9U3iojrI6I1IlonT568xwGbmVljRSaLe4GjJM2U1AwsBG4bYt+ngFMlVSQ1kVzc9mkoM7MxUliyiIhuYAlwJ8lAf2NErJN0taRzASSdJKkd+CBwnaR1afebgceBh4C1wNqI+FFRsZqZ2eD0WnlKVWtra7S1tY11GGZmexVJ90VEa147f4PbzMxyOVmYmVkuJwszM8vlZGFmZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVkuJwszM8vlZGFmZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVkuJwszM8tVaLKQNF/SRkmbJC1tUH+KpPsldUs6r65umqSVktZLekTSjCJjNTOzgRWWLCSVgeXAOcAsYJGkWXXNngIuAP6lwSq+AyyLiKOBk4HniorVzMwGVylw3ScDmyLiCQBJK4AFwCPVBhGxOa3rzXZMk0olIlal7bYXGKeZmeUo8jTUEcCWzHJ7WjYUbwZelPQDSQ9IWpYeqfQhabGkNkltW7duHYGQzcyskSKThRqUxRD7VoB5wGeBk4AjSU5X9V1ZxPUR0RoRrZMnT97dOM3MLEeRyaIdmJpZngI8M4y+D0TEExHRDfwQOHGE4zMzsyEqMlncCxwlaaakZmAhcNsw+h4oqXq4cBqZax1mZja6CksW6RHBEuBOYD1wY0Ssk3S1pHMBJJ0kqR34IHCdpHVp3x6SU1B3SXqI5JTWN4qK1czMBqeIoV5GeHVrbW2Ntra2sQ7DzGyvIum+iGjNa+dvcJuZWS4nCzMzy+VkYWZmuZwszMwsl5OFmZnlcrIwM7NcThZmZpbLycLMzHI5WZiZWS4nCzMzy+VkYWZmuZwszMwsl5OFmZnlcrIwM7NcThZmZpbLycLMzHI5WZiZWS4nCzMzy1VospA0X9JGSZskLW1Qf4qk+yV1SzqvQf3rJD0t6atFxmlmZoMrLFlIKgPLgXOAWcAiSbPqmj0FXAD8ywCr+Tvgp0XFaGZmQ1PkkcXJwKaIeCIiOoEVwIJsg4jYHBEPAr31nSXNBQ4BVhYYo5mZDUGRyeIIYEtmuT0tyyWpBFwLfK6AuMzMbJiKTBZqUBZD7Hsp8JOI2DJYI0mLJbVJatu6deuwAzQzs6GpFLjudmBqZnkK8MwQ+74dmCfpUmB/oFnS9ojoc5E8Iq4HrgdobW0daiIyM7NhKjJZ3AscJWkm8DSwEPjPQ+kYER+pzku6AGitTxRmZjZ6CjsNFRHdwBLgTmA9cGNErJN0taRzASSdJKkd+CBwnaR1RcVjZma7TxGvjbM3ra2t0dbWNtZhmJntVSTdFxGtee38DW4zM8tV5DULMzMAIoLegJ7eoDeCnt6gJ4Le3v7lvRH09kJPuhwRtfneXpJ2ad+etH+fvpn+tfVHup5q++r2G8SQrIu+dbX5SNe1ax3Rpy/929V+DvqsP6rzQSa2vuvordbFrp+9ts7M/NGHvo6v/8XcQn+HThZme6D6R96dTj09QXdvb61s12tv0qZn10DZ02+5l+6eZJCo9s2up9+UXUfav6eX2muynnQ+Mzh3V/v29C2rDeJ9BnR21WfWsWvwrs5nBuxsfWaA3tuVBCWJUkmUBGWp73JJSLvqJKVladu0XUmZdmmfcmbdAporpT7rK/V5FaUSaV3Sd/qkCYX//E4WNqoiHQg7u5OBsbOnl66exvPdPb109QRdvb10dSeDbVda1t3TS1dv8tqdtumuK+/KDNzVPtUBuzszeHf1pG16dw3Y1QG6Wtfdu6t//QD+alEuJYNTOR2kqlNJolzaNWBV6uoqZdXqdrUpMa6yq31tHbX5/n2y26jGUKprVy7Rtz4zaGbbVrdX6tOuOt93HdXBuLqOZABNy0uZPpl1VOsarbfav1TdfrouqdFXx/YdThavcRHJQLmzu4eOrl46unvYmb52dPfWyjq7e5Pl7t50Pinr7O6lsydbvqusK33tzLx29fTWBvRau7RtV5oEitZUTga7Slk0lUtU0gGvUk7KKulg2FROBolKucS4phL7lXa1bSon/9kl/dJ2paQs6Ze0LZVEU0mUy9VBuK68bl3ZwbpSKlEqUVtvuU9d34G6GkNZu/qVs+vxYGYFc7IYY53dvezo7OaPnT3s6OhmR2cPf+zsZkdHDzu6enils5tXOqvz6dSVTDu7koG/WrazK0kAOzN1Hd09e3wKQIJxlRLN5RLNlTLjKslA21wpJVO5RFO5xMSWStomWW4ql2iuqFbflJY3l5MBurlalg6olXLStlJO15+Zb6oN9KW0PBlAm+qSQvXQ3cxGlpPFHtjZ1cNLr3TVphd3dPHyK128vLOLP+zs5g87u9je0c3LO7v5w85u/tiRTNvT6Y8d3XT1DH0kl2B8U5nxTWVamsqMby7T0lRifFOZiS0VJk8cR0tTmZZKKXltqr4mA/y46mta31wp0VJJXsfVpnItCYxLXysegM32eU4WGV09vfx+ewdb/9DBcy93sHV7B9u2d7Dtj508n07btievL+zopKN78FMqLU0lJrY0MXFchYktFfZvqTBpwn7sP67ChHTaf1yZCeMq7NdcZr/mChPGlRnflCxPGJcM9Ps1J8vjKiUP2mY2Jvb5ZLH1Dx189Ju/Yuv2Dp7/Y2fDNvuPq3DQhGYOmtDMoQe0MOvw13HQhGYOGN/EAeObeP1+TbX5A8Y3MbGlif3HVWiu+GssZvbasM8ni4ktFaZP2o/WGQcyeeI4Dp7YwuSJ42rTpAnNtDSVxzpMM7Mxtc8ni5amMtd/LPeb7mZm+zSfJzEzs1xOFmZmlsvJwszMcjlZmJlZLicLMzPL5WRhZma5nCzMzCyXk4WZmeV6zTyDW9JW4Mk9WMUbgN+PUDgjyXENj+MaHsc1PK/FuKZHxOS8Rq+ZZLGnJLUN5aHlo81xDY/jGh7HNTz7clw+DWVmZrmcLMzMLJeTxS7Xj3UAA3Bcw+O4hsdxDc8+G5evWZiZWS4fWZiZWa59KllImi9po6RNkpY2qB8n6ftp/a8kzRiFmKZKulvSeknrJH2qQZt3S3pJ0pp0+qui48pse7Okh9LttjWol6SvpPvsQUknjkJMb8nsizWSXpb06bo2o7LPJH1L0nOSHs6UHSRplaTH0tcDB+h7ftrmMUnnj0JcyyRtSH9P/yrp9QP0HfR3XkBcfyPp6czv6j0D9B3077eAuL6fiWmzpDUD9C1yfzUcH8bkPRYR+8QElIHHgSOBZmAtMKuuzaXA19P5hcD3RyGuw4AT0/mJwKMN4no38OMx2m+bgTcMUv8e4HZAwNuAX43B7/W3JJ8VH/V9BpwCnAg8nCm7Bliazi8Fvtig30HAE+nrgen8gQXHdRZQSee/2CiuofzOC4jrb4DPDuH3POjf70jHVVd/LfDdIuykAAAFJklEQVRXY7C/Go4PY/Ee25eOLE4GNkXEExHRCawAFtS1WQDckM7fDJwuSUUGFRHPRsT96fwfgPXAEUVuc4QtAL4TidXA6yUdNorbPx14PCL25AuZuy0i7gGeryvOvo9uAP6sQdezgVUR8XxEvACsAuYXGVdErIyI7nRxNTBlpLa3J3EN0VD+fguJKx0DPgR8b6S2N1SDjA+j/h7bl5LFEcCWzHI7/QflWpv0j+olYNKoRAekp71OAH7VoPrtktZKul3SMaMVExDASkn3SVrcoH4o+7VICxn4j3is9tkhEfEsJH/swMEN2oz1fruI5IiwkbzfeRGWpKfHvjXAKZWx3F/zgN9FxGMD1I/K/qobH0b9PbYvJYtGRwj1HwUbSptCSNofuAX4dES8XFd9P8lpluOBfwR+OBoxpd4ZEScC5wCXSTqlrn4s91kzcC5wU4PqsdxnQzGW++0LQDfwzwM0yfudj7T/DbwRmAM8S3LKp96Y7S9gEYMfVRS+v3LGhwG7NSjb7X22LyWLdmBqZnkK8MxAbSRVgAPYvUPmYZHURPJG+OeI+EF9fUS8HBHb0/mfAE2S3lB0XOn2nklfnwP+leR0QNZQ9mtRzgHuj4jf1VeM5T4Dflc9FZe+PtegzZjst/Qi53uBj0R6YrveEH7nIyoifhcRPRHRC3xjgO2N1f6qAH8OfH+gNkXvrwHGh1F/j+1LyeJe4ChJM9P/SBcCt9W1uQ2ofmLgPOD/DvQHNVLS86H/B1gfEf9rgDaHVq+dSDqZ5Pe2rci40m1NkDSxOk9ygfThuma3AR9T4m3AS9XD41Ew4H98Y7XPUtn30fnArQ3a3AmcJenA9LTLWWlZYSTNB/4bcG5E7BigzVB+5yMdV/Ya1/sH2N5Q/n6LcAawISLaG1UWvb8GGR9G/z1WxBX8V+tE8smdR0k+VfGFtOxqkj8egBaSUxqbgF8DR45CTO8iOTR8EFiTTu8B/hL4y7TNEmAdySdAVgPvGKX9dWS6zbXp9qv7LBubgOXpPn0IaB2l2PYjGfwPyJSN+j4jSVbPAl0k/8ldTHKd6y7gsfT1oLRtK/DNTN+L0vfaJuDCUYhrE8k57Or7rPrJv8OBnwz2Oy84ru+m750HSQbBw+rjSpf7/f0WGVda/k/V91Sm7Wjur4HGh1F/j/kb3GZmlmtfOg1lZma7ycnCzMxyOVmYmVkuJwszM8vlZGFmZrmcLMx2g6T3SwpJb02XZ2TvWDpAn9w2Zq9WThZmu2cR8HOSL4eZveY5WZgNU3qfnneSfKGsX7KQdIGkWyXdkT5/4a8z1WVJ30ifTbBS0vi0z3+RdG9648NbJO03Oj+N2dA4WZgN358Bd0TEo8DzavzAp5OBj5DcHO+DklrT8qOA5RFxDPAi8IG0/AcRcVIkNz5cT5KIzF41nCzMhm8RyfMUSF8XNWizKiK2RcQrwA9IbtsA8JuIqD5x7T5gRjo/W9LPJD1EkmRG85bqZrkqYx2A2d5E0iTgNJLBPUie4BbA1+qa1t9Hp7rckSnrAcan8/8E/FlErJV0AcmT/sxeNXxkYTY855E8GXB6RMyIiKnAb+j/1Lkz0+ckjyc5bfX/ctY7EXg2vR31R0Y8arM95GRhNjyLSJ5ZkHUL8N/ryn5OcjfVNcAtEdGWs96rSJ6AtgrYMAJxmo0o33XWbISlp5FaI2LJWMdiNlJ8ZGFmZrl8ZGFmZrl8ZGFmZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxy/X9G/3IIfayKPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.plot(alpha, t_rmse, label='RMSE-Train') #plot ridge regression \n",
    "pl.plot(alpha, cv_rmse, label='RMSE_XVal')\n",
    "pl.legend( ('RMSE-Train', 'RMSE_XVal') )\n",
    "pl.ylabel('RMSE')\n",
    "pl.xlabel('Alpha')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: linear regression\n",
      "RMSE on training: 0.1289\n",
      "RMSE on 5-fold CV: 0.1376\n",
      "\n",
      "\n",
      "Method: lasso\n",
      "RMSE on training: 0.2329\n",
      "RMSE on 5-fold CV: 0.2331\n",
      "\n",
      "\n",
      "Method: ridge\n",
      "RMSE on training: 0.1290\n",
      "RMSE on 5-fold CV: 0.1369\n",
      "\n",
      "\n",
      "Method: elastic-net\n",
      "RMSE on training: 0.2329\n",
      "RMSE on 5-fold CV: 0.2331\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 0.4 #code taken frm regression python notebook discussed in class, aplha selected above \n",
    "for name,met in [\n",
    "        ('linear regression', LinearRegression()),\n",
    "        ('lasso', Lasso(fit_intercept=True, alpha=a)),\n",
    "        ('ridge', Ridge(fit_intercept=True, alpha=a)),\n",
    "        ('elastic-net', ElasticNet(fit_intercept=True, alpha=a))\n",
    "        ]:\n",
    "    met.fit(x,targetY)\n",
    "    p = met.predict(x)\n",
    "    e = p-targetY\n",
    "    total_error = np.dot(e,e)\n",
    "    rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "    kf = KFold(len(x), n_folds=5)\n",
    "    err = 0\n",
    "    for train,test in kf:\n",
    "        met.fit(x[train],targetY[train])\n",
    "        p = met.predict(x[test])\n",
    "        e = p-targetY[test]\n",
    "        err += np.dot(e,e)\n",
    "    rmse_10cv = np.sqrt(err/len(x))\n",
    "    \n",
    "    print('Method: %s' %name)\n",
    "    print('RMSE on training: %.4f' %rmse_train)\n",
    "    print('RMSE on 5-fold CV: %.4f' %rmse_10cv)\n",
    "    print (\"\\n\")\n",
    "\n",
    "# we See that K fold CV valdition performed better for lasso and elastic-net regression than for ridge or standard \n",
    "#linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Stochastic Gradient Descent Regression\n",
      "RMSE on training: 0.1328\n",
      "RMSE on 10-fold CV: 0.1367\n"
     ]
    }
   ],
   "source": [
    "#1E Next, perform regression using Stochastic Gradient Descent for regression.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x_s = scaler.transform(x)\n",
    "\n",
    "sgdreg = SGDRegressor(penalty='l2', alpha=0.1, n_iter=300)\n",
    "\n",
    "# Compute RMSE on training data\n",
    "sgdreg.fit(x_s,targetY)\n",
    "p = sgdreg.predict(x_s)\n",
    "err = p-targetY\n",
    "total_error = np.dot(err,err)\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "# Compute RMSE using 10-fold x-validation\n",
    "kf = KFold(len(x), n_folds=10)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x[train])  # Don't cheat - fit only on training data\n",
    "    xtrain_s = scaler.transform(x[train])\n",
    "    xtest_s = scaler.transform(x[test])  # apply same transformation to test data\n",
    "    sgdreg.fit(xtrain_s,targetY[train])\n",
    "    p = sgdreg.predict(xtest_s)\n",
    "    e = p-targetY[test]\n",
    "    xval_err += np.dot(e,e)\n",
    "rmse_10cv = np.sqrt(xval_err/len(x))\n",
    "\n",
    "method_name = 'Stochastic Gradient Descent Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Sebastian/Graduate School/DSC - 478 Machine Learning /HW/HW 3/newsgroups5'"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 2 \n",
    "\n",
    "## Get working directory\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change working directory\n",
    "os.chdir('/Users/Sebastian/Graduate School/DSC - 478 Machine Learning /HW/HW 3/newsgroups5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1\n",
       "0  0\n",
       "1  1\n",
       "2  1\n",
       "3  1\n",
       "4  2\n",
       "5  1\n",
       "6  3\n",
       "7  4\n",
       "8  1\n",
       "9  1"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading in dataset \n",
    "\n",
    "class_x = pd.DataFrame(np.genfromtxt(\"classes.txt\", delimiter=' ', dtype=int, skip_header=1))\n",
    "\n",
    "#populate train classes data into dataframe\n",
    "\n",
    "\n",
    "#class_x\n",
    "class_x = class_x.drop(class_x.columns[0], axis=1)\n",
    "class_x.head(10)\n",
    "#class_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 9328)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix_x = pd.DataFrame(np.genfromtxt(\"matrix.txt\", delimiter=',', dtype=int))\n",
    "#matrix_x.shape\n",
    "\n",
    "#populate data into dataframe\n",
    "matrix_x = pd.read_csv(\"matrix.txt\", header=None,sep=',')\n",
    "matrix_x_np = np.array(matrix_x).T #transpose so we get same rows as classes\n",
    "matrix_x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        aa\n",
       "1     aargh\n",
       "2     aaron\n",
       "3    aaronc\n",
       "4        ab\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_x = pd.DataFrame(np.genfromtxt(\"terms.txt\", delimiter='\\t', dtype=str))\n",
    "terms_x.shape\n",
    "terms_x_np = np.array(terms_x)\n",
    "terms_x_np.shape\n",
    "#all data has been loaded in \n",
    "\n",
    "terms_xc = pd.read_csv(\"terms.txt\", header=None,sep='\\t')\n",
    "\n",
    "\n",
    "terms_xc = terms_x.loc[:,0]\n",
    "terms_xc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9328)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create testing / training set data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(matrix_x_np, class_x, test_size = 0.2, random_state = 33)\n",
    "#do 80 / 20 split \n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "/Users/Sebastian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "#set up document term matrix \n",
    "news_train = x_train.T\n",
    "\n",
    "\n",
    "# Find doc freq for each term within matrix \n",
    "z = np.array([(news_train!=0).sum(1)]).T\n",
    "\n",
    "m_document_number = x_train.shape[0] #amount of docments in matrix \n",
    "m_term_number = x_train.shape[1] #terms per matrix \n",
    "\n",
    "term_ferq = news_train.sum(axis=1)\n",
    "#create matrix that contains all terms \n",
    "updateM = np.ones(np.shape(news_train),dtype = float) * m_document_number\n",
    "\n",
    "#transform for IDF term matrix\n",
    "IDF = np.log2(np.divide(updateM, z))\n",
    "\n",
    "TFIDF_train = np.array(news_train * IDF)\n",
    "\n",
    "\n",
    "TFIDF_train_2 = TFIDF_train.T #transpose matrix \n",
    "\n",
    "#check nulls/reduce any scalers so we dont error out during Kmeans \n",
    "TFIDF_train_2[np.isnan(TFIDF_train_2)] = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(m_term_number)\n",
    "#print(m_document_number)\n",
    "\n",
    "\n",
    "#print(term_ferq)\n",
    "#print(updateterm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create term-freqency dictionary\n",
    "dictTF = {}\n",
    "for i in range(m_term_number):\n",
    "               dictTF[terms_xc[i]] = term_ferq[i]\n",
    "#print (sorted(dictTF.items()))\n",
    "sortedTF = sorted(dictTF.values(), reverse=True)\n",
    "#print (sortedTF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1A.Create your own distance function that, instead of using Euclidean distance, uses Cosine similarity. \n",
    "#This is the distance function you will use to pass to the kMeans function\n",
    "#cosine similarity distance\n",
    "def cos_sim(a,b):\n",
    "    #a_norm = np.linealg.norm(a)\n",
    "    #b_norm = np.linalg.norm(b)\n",
    "    cos_sim = dot(a, b)/((np.linalg.norm(a))*(np.linalg.norm(b)))\n",
    "    distance = 1 - cos_sim\n",
    "    return distance\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2C .Perform Kmeans clustering on the training data. \n",
    "#Write a function to display the top N terms in each cluster along with the \n",
    "#cluster DF values for each term and the size of the cluster. \n",
    "\n",
    "\n",
    "#Created on Feb 16, 2011\n",
    "#k Means Clustering for Ch10 of Machine Learning in Action\n",
    "#@author: Peter Harrington\n",
    "#2'''\n",
    "from numpy import *\n",
    "\n",
    "def distEuclid(vecA, vecB):\n",
    "    return sqrt(sum(power(vecA - vecB, 2))) #la.norm(vecA-vecB)\n",
    "\n",
    "def randCent(dataSet, k):\n",
    "    n = shape(dataSet)[1]\n",
    "    centroids = zeros((k,n), dtype=float)\n",
    "    for j in range(n): #create random cluster centers\n",
    "        minJ = min(dataSet[:,j])\n",
    "        rangeJ = float(max(dataSet[:,j]) - minJ)\n",
    "        centroids[:,j] = minJ + rangeJ * random.rand(k)\n",
    "    return centroids \n",
    "\n",
    "def kMeans(dataSet, k, distMeas=cos_sim, createCent=randCent):\n",
    "    m = shape(dataSet)[0]\n",
    "    clusterAssment = zeros((m,2))#create mat to assign data points \n",
    "                                      #to a centroid, also holds SE of each point\n",
    "    centroids = createCent(dataSet, k)\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        for i in range(m):#for each data point assign it to the closest centroid\n",
    "            minDist = inf; minIndex = -1\n",
    "            for j in range(k):\n",
    "                distJI = distMeas(centroids[j,:],dataSet[i,:])\n",
    "                if distJI < minDist:\n",
    "                    minDist = distJI; minIndex = j\n",
    "            if clusterAssment[i,0] != minIndex: clusterChanged = True\n",
    "            clusterAssment[i,:] = minIndex,minDist**2\n",
    "        # print centroids\n",
    "        for cent in range(k):#recalculate centroids\n",
    "            ptsInClust = dataSet[nonzero(clusterAssment[:,0]==cent)[0]] #get all the point in this cluster - Note: this was incorrect in the original distribution.\n",
    "            if(len(ptsInClust)!=0):\n",
    "                centroids[cent,:] = mean(ptsInClust, axis=0) #assign centroid to mean - Note condition was added 10/28/2013\n",
    "    return centroids, clusterAssment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run k means function get centriods and clusters\n",
    "centroids, clusters = kMeans(TFIDF_train_2, 5, distMeas= cos_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04729524 0.         0.         ... 0.05777266 0.03178488 0.17331799]\n",
      " [0.00978229 0.04300136 0.5443276  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 1.24572304 0.         0.        ]\n",
      " [0.04328079 0.         0.07297954 ... 0.         0.         0.        ]\n",
      " [0.03742399 0.         0.0473279  ... 0.         0.         0.        ]]\n",
      "[3.         0.79455678]\n",
      "[4.         0.90717614]\n",
      "[3.         0.74759438]\n",
      "[3.        0.7431077]\n",
      "[0.         0.77789536]\n",
      "[1.         0.72358976]\n",
      "[4.         0.59927222]\n",
      "[1.         0.71872928]\n",
      "[1.         0.88740746]\n",
      "[3.        0.6286945]\n",
      "[3.         0.67390122]\n",
      "[1.         0.66239237]\n",
      "[3.         0.51277903]\n",
      "[1.         0.69024717]\n",
      "[1.         0.78000884]\n",
      "[1.         0.86120841]\n",
      "[4.         0.52459449]\n",
      "[1.         0.84671451]\n",
      "[3.         0.79730249]\n",
      "[3.         0.58030208]\n",
      "[1.         0.78468566]\n",
      "[4.         0.77464011]\n",
      "[4.         0.48784101]\n",
      "[1.        0.8270334]\n",
      "[3.         0.63453378]\n",
      "[3.         0.74855176]\n",
      "[1.         0.92724346]\n",
      "[1.         0.71367233]\n",
      "[1.         0.79410719]\n",
      "[1.         0.78589488]\n",
      "[1.         0.75585794]\n",
      "[1.         0.59234394]\n",
      "[4.         0.48017958]\n",
      "[1.         0.73236635]\n",
      "[1.         0.81488732]\n",
      "[1.         0.68160417]\n",
      "[1.         0.70695419]\n",
      "[4.         0.46453668]\n",
      "[3.        0.6796436]\n",
      "[1.         0.90943415]\n",
      "[1.         0.91663919]\n",
      "[0.         0.84612119]\n",
      "[1.         0.67017902]\n",
      "[4.         0.83949654]\n",
      "[0.         0.55086979]\n",
      "[0.         0.73656065]\n",
      "[4.         0.79226784]\n",
      "[1.         0.82914226]\n",
      "[3.         0.73588028]\n",
      "[4.         0.45527582]\n",
      "[1.         0.76661874]\n",
      "[4.         0.70769243]\n",
      "[1.         0.74032667]\n",
      "[1.         0.73220958]\n",
      "[1.         0.78071538]\n",
      "[1.         0.68842958]\n",
      "[1.         0.68782488]\n",
      "[1.         0.74124545]\n",
      "[0.         0.75363405]\n",
      "[1.         0.77261259]\n",
      "[4.         0.62689497]\n",
      "[1.         0.68813336]\n",
      "[1.         0.90981469]\n",
      "[3.         0.60287364]\n",
      "[4.        0.6237531]\n",
      "[4.        0.8792352]\n",
      "[4.         0.70795082]\n",
      "[1.         0.71529095]\n",
      "[1.         0.71297192]\n",
      "[3.         0.62141196]\n",
      "[1.         0.62090285]\n",
      "[3.         0.81201793]\n",
      "[1.         0.76179325]\n",
      "[1.         0.89735524]\n",
      "[0.        0.7081416]\n",
      "[4.         0.61537683]\n",
      "[1.         0.84997642]\n",
      "[0.         0.75022125]\n",
      "[1.         0.60725985]\n",
      "[1.         0.70333262]\n",
      "[1.         0.70944167]\n",
      "[3.        0.8364962]\n",
      "[4.         0.76575247]\n",
      "[3.         0.82451528]\n",
      "[3.         0.82969143]\n",
      "[3.         0.82087366]\n",
      "[0.         0.76773227]\n",
      "[4.         0.49351219]\n",
      "[0.         0.47165594]\n",
      "[1.         0.75375762]\n",
      "[0.         0.37832447]\n",
      "[3.         0.58356038]\n",
      "[3.         0.54436867]\n",
      "[1.         0.70034025]\n",
      "[4.         0.53716718]\n",
      "[1.         0.88664524]\n",
      "[1.         0.86825055]\n",
      "[3.         0.76317035]\n",
      "[1.         0.55704512]\n",
      "[3.         0.68849561]\n",
      "[0.         0.69535269]\n",
      "[3.       0.738345]\n",
      "[4.         0.58760519]\n",
      "[1.         0.65989907]\n",
      "[4.         0.66963627]\n",
      "[3.         0.76791396]\n",
      "[3.         0.77247751]\n",
      "[0.         0.68426938]\n",
      "[3.         0.51071047]\n",
      "[0.         0.62052441]\n",
      "[4.         0.61425271]\n",
      "[0.         0.73745018]\n",
      "[1.         0.70411636]\n",
      "[3.         0.61310481]\n",
      "[4.         0.50947336]\n",
      "[1.         0.57738925]\n",
      "[4.       0.612627]\n",
      "[3.         0.62276575]\n",
      "[3.         0.85361385]\n",
      "[4.        0.7981231]\n",
      "[0.         0.76450828]\n",
      "[0.         0.71541582]\n",
      "[1.         0.81924458]\n",
      "[4.         0.53672644]\n",
      "[3.         0.79749956]\n",
      "[1.         0.71250335]\n",
      "[1.         0.75017992]\n",
      "[0.         0.71875692]\n",
      "[0.         0.64693361]\n",
      "[4.         0.66908523]\n",
      "[1.         0.70796514]\n",
      "[1.         0.61730622]\n",
      "[4.         0.56058681]\n",
      "[1.         0.73118535]\n",
      "[0.         0.89383388]\n",
      "[4.         0.55832489]\n",
      "[0.         0.81260541]\n",
      "[4.         0.83487329]\n",
      "[4.         0.59828725]\n",
      "[3.         0.71533887]\n",
      "[3.         0.39717653]\n",
      "[1.         0.72829641]\n",
      "[1.         0.66707619]\n",
      "[0.         0.82379885]\n",
      "[4.         0.54839928]\n",
      "[4.         0.66863795]\n",
      "[1.         0.47173039]\n",
      "[1.         0.73318005]\n",
      "[1.         0.72978906]\n",
      "[0.         0.60911428]\n",
      "[3.         0.74800488]\n",
      "[3.         0.48730427]\n",
      "[0.         0.89113201]\n",
      "[4.         0.88947368]\n",
      "[1.         0.73008576]\n",
      "[1.         0.49247554]\n",
      "[1.         0.85847121]\n",
      "[1.         0.85678963]\n",
      "[1.        0.7848826]\n",
      "[0.         0.86479934]\n",
      "[1.         0.59942882]\n",
      "[4.         0.91318216]\n",
      "[3.         0.75836642]\n",
      "[1.         0.72964111]\n",
      "[3.         0.62791886]\n",
      "[0.         0.76243552]\n",
      "[0.         0.77067228]\n",
      "[1.         0.84556165]\n",
      "[1.         0.80270521]\n",
      "[4.         0.58660114]\n",
      "[1.         0.70915026]\n",
      "[1.         0.79807655]\n",
      "[1.       0.780034]\n",
      "[1.         0.67366573]\n",
      "[4.         0.56847963]\n",
      "[1.         0.74478215]\n",
      "[1.         0.73754728]\n",
      "[0.         0.71061648]\n",
      "[1.         0.73720951]\n",
      "[1.         0.67413486]\n",
      "[3.       0.793504]\n",
      "[1.         0.80889305]\n",
      "[1.         0.79915841]\n",
      "[0.        0.5560191]\n",
      "[1.        0.8495561]\n",
      "[3.         0.71671563]\n",
      "[3.        0.6816605]\n",
      "[3.         0.78022472]\n",
      "[1.         0.83459852]\n",
      "[1.        0.7398282]\n",
      "[1.         0.53588626]\n",
      "[3.         0.52151866]\n",
      "[0.         0.68044201]\n",
      "[0.         0.48445702]\n",
      "[4.         0.58916787]\n",
      "[3.         0.50257944]\n",
      "[3.         0.67970606]\n",
      "[1.         0.65151941]\n",
      "[3.         0.75731372]\n",
      "[1.         0.92308638]\n",
      "[1.         0.45172142]\n",
      "[3.         0.68595014]\n",
      "[4.         0.47986352]\n",
      "[1.         0.80338674]\n",
      "[1.         0.64800237]\n",
      "[1.         0.82024335]\n",
      "[1.         0.76126993]\n",
      "[1.         0.82379963]\n",
      "[3.         0.78649511]\n",
      "[1.         0.74784257]\n",
      "[4.         0.70609459]\n",
      "[0.         0.75761354]\n",
      "[3.         0.66290739]\n",
      "[4.         0.68016861]\n",
      "[3.         0.60692944]\n",
      "[1.         0.79821293]\n",
      "[0.         0.54702158]\n",
      "[3.         0.74272574]\n",
      "[3.         0.71976328]\n",
      "[4.         0.74598744]\n",
      "[4.         0.62592138]\n",
      "[1.         0.53955128]\n",
      "[3.         0.72973798]\n",
      "[1.         0.73699205]\n",
      "[0.         0.86375382]\n",
      "[0.         0.62901537]\n",
      "[1.         0.80833421]\n",
      "[3.         0.80988138]\n",
      "[1.         0.70696538]\n",
      "[0.         0.35576312]\n",
      "[1.         0.69682015]\n",
      "[1.         0.81137827]\n",
      "[1.         0.67541615]\n",
      "[1.         0.70595383]\n",
      "[1.         0.61916575]\n",
      "[0.         0.78468633]\n",
      "[3.         0.51616086]\n",
      "[3.         0.71124149]\n",
      "[1.         0.89253372]\n",
      "[1.         0.73651798]\n",
      "[1.         0.90614012]\n",
      "[1.         0.82763011]\n",
      "[1.         0.79860412]\n",
      "[1.         0.83083302]\n",
      "[3.         0.76348925]\n",
      "[1.        0.9103542]\n",
      "[4.         0.66907757]\n",
      "[0.         0.67226546]\n",
      "[4.         0.44003171]\n",
      "[1.         0.52378035]\n",
      "[1.         0.74834346]\n",
      "[4.         0.70097811]\n",
      "[4.         0.72497621]\n",
      "[1.         0.82549736]\n",
      "[0.         0.41370055]\n",
      "[1.         0.83571315]\n",
      "[4.         0.63929053]\n",
      "[1.        0.7761673]\n",
      "[4.         0.67867845]\n",
      "[0.         0.88366496]\n",
      "[0.         0.64763486]\n",
      "[4.         0.65263654]\n",
      "[3.         0.80994613]\n",
      "[1.         0.82082462]\n",
      "[1.         0.73017069]\n",
      "[0.         0.57055209]\n",
      "[3.         0.63137026]\n",
      "[1.         0.72946855]\n",
      "[3.         0.80890528]\n",
      "[4.         0.70651624]\n",
      "[0.         0.76843511]\n",
      "[3.        0.6785072]\n",
      "[3.         0.66456655]\n",
      "[4.        0.7780716]\n",
      "[1.         0.72563626]\n",
      "[1.         0.62286835]\n",
      "[4.        0.5142142]\n",
      "[3.         0.65609587]\n",
      "[3.         0.58383017]\n",
      "[3.         0.55906745]\n",
      "[3.         0.78020906]\n",
      "[3.         0.76546175]\n",
      "[4.         0.52236682]\n",
      "[1.         0.79934973]\n",
      "[4.         0.56801809]\n",
      "[4.         0.75285503]\n",
      "[1.         0.74828419]\n",
      "[1.        0.6636332]\n",
      "[0.         0.54797339]\n",
      "[4.         0.70054947]\n",
      "[4.         0.69747812]\n",
      "[0.         0.54587666]\n",
      "[1.         0.74304348]\n",
      "[1.         0.53279679]\n",
      "[1.         0.72635274]\n",
      "[0.         0.61305923]\n",
      "[1.         0.84955085]\n",
      "[0.         0.54086921]\n",
      "[3.         0.56462839]\n",
      "[1.         0.59220111]\n",
      "[4.         0.74107165]\n",
      "[1.         0.70638027]\n",
      "[0.         0.74056742]\n",
      "[4.         0.77113613]\n",
      "[4.        0.8032974]\n",
      "[1.        0.6952677]\n",
      "[4.         0.66380051]\n",
      "[1.         0.78395146]\n",
      "[3.         0.77254856]\n",
      "[4.         0.67752598]\n",
      "[3.        0.7440073]\n",
      "[0.         0.84770805]\n",
      "[1.         0.60528035]\n",
      "[3.        0.6455368]\n",
      "[0.         0.57654442]\n",
      "[4.         0.82214282]\n",
      "[3.         0.58950886]\n",
      "[1.         0.79442101]\n",
      "[4.         0.62900324]\n",
      "[1.         0.80466861]\n",
      "[3.         0.58423569]\n",
      "[1.         0.62204217]\n",
      "[0.         0.81750851]\n",
      "[4.        0.7679859]\n",
      "[2.         0.90484241]\n",
      "[1.         0.85604936]\n",
      "[3.         0.78724762]\n",
      "[4.         0.71690043]\n",
      "[4.         0.67307039]\n",
      "[3.         0.82142874]\n",
      "[1.         0.61021537]\n",
      "[1.         0.73438808]\n",
      "[0.         0.82102787]\n",
      "[1.         0.52825981]\n",
      "[1.         0.60228674]\n",
      "[0.         0.61783099]\n",
      "[1.         0.84791878]\n",
      "[1.         0.89740633]\n",
      "[0.         0.64744515]\n",
      "[4.         0.79756295]\n",
      "[4.         0.69755459]\n",
      "[0.         0.44791407]\n",
      "[1.         0.77232875]\n",
      "[1.         0.72150422]\n",
      "[0.         0.76668037]\n",
      "[1.         0.79859001]\n",
      "[1.         0.72079743]\n",
      "[1.         0.76449288]\n",
      "[1.         0.81986921]\n",
      "[1.         0.78352336]\n",
      "[3.         0.80726132]\n",
      "[1.         0.52159143]\n",
      "[0.         0.66343829]\n",
      "[4.         0.70731741]\n",
      "[1.         0.65029037]\n",
      "[1.         0.64534515]\n",
      "[1.         0.73322022]\n",
      "[4.         0.74855466]\n",
      "[4.         0.84799931]\n",
      "[0.         0.62834564]\n",
      "[4.         0.81782622]\n",
      "[3.        0.7251531]\n",
      "[3.         0.61805168]\n",
      "[1.         0.75219148]\n",
      "[1.         0.76627159]\n",
      "[1.         0.71694071]\n",
      "[0.         0.63997666]\n",
      "[3.         0.86492697]\n",
      "[1.         0.70760153]\n",
      "[1.         0.56957985]\n",
      "[1.        0.7092689]\n",
      "[4.         0.45303836]\n",
      "[1.         0.56275779]\n",
      "[3.         0.63198895]\n",
      "[1.        0.6211572]\n",
      "[4.         0.79273204]\n",
      "[4.         0.54710992]\n",
      "[4.         0.87288727]\n",
      "[1.       0.777726]\n",
      "[0.         0.66408267]\n",
      "[1.         0.63045378]\n",
      "[1.        0.9144702]\n",
      "[0.         0.68682926]\n",
      "[1.         0.92317445]\n",
      "[4.         0.66834464]\n",
      "[3.         0.77325604]\n",
      "[4.        0.8044405]\n",
      "[4.         0.71757823]\n",
      "[0.         0.87986127]\n",
      "[3.         0.68613167]\n",
      "[0.         0.68567583]\n",
      "[1.         0.69398637]\n",
      "[3.         0.59042692]\n",
      "[4.         0.59085506]\n",
      "[4.         0.67784621]\n",
      "[4.         0.69782069]\n",
      "[4.         0.58936934]\n",
      "[3.         0.73384411]\n",
      "[0.         0.87530448]\n",
      "[1.         0.78407328]\n",
      "[0.         0.59890311]\n",
      "[1.         0.86742586]\n",
      "[4.         0.73915382]\n",
      "[3.         0.59940614]\n",
      "[1.         0.64303892]\n",
      "[1.         0.62629326]\n",
      "[1.         0.76166967]\n",
      "[1.         0.67900608]\n",
      "[4.         0.83788217]\n",
      "[1.         0.93578696]\n",
      "[1.         0.94547373]\n",
      "[0.         0.79494574]\n",
      "[0.         0.56213894]\n",
      "[1.         0.68293568]\n",
      "[0.         0.73862549]\n",
      "[0.         0.71307051]\n",
      "[1.        0.7730215]\n",
      "[3.         0.83615504]\n",
      "[1.         0.72286256]\n",
      "[3.         0.70319391]\n",
      "[3.         0.71837513]\n",
      "[0.        0.4838636]\n",
      "[3.         0.88189199]\n",
      "[4.        0.8472281]\n",
      "[1.        0.6510081]\n",
      "[1.         0.70967352]\n",
      "[0.         0.78553613]\n",
      "[0.         0.78155607]\n",
      "[0.         0.60284008]\n",
      "[0.         0.74205177]\n",
      "[4.         0.60287022]\n",
      "[4.         0.73266218]\n",
      "[3.         0.80756985]\n",
      "[4.         0.81692003]\n",
      "[2.00000000e+00 1.14007184e-07]\n",
      "[4.         0.70580883]\n",
      "[1.         0.70415869]\n",
      "[3.         0.66319681]\n",
      "[4.         0.69121037]\n",
      "[0.         0.62152141]\n",
      "[0.        0.7837588]\n",
      "[0.         0.63076536]\n",
      "[3.         0.40965297]\n",
      "[1.         0.49686066]\n",
      "[4.         0.78412738]\n",
      "[1.         0.62759817]\n",
      "[1.         0.68977673]\n",
      "[4.       0.696396]\n",
      "[3.         0.66643454]\n",
      "[1.         0.78792056]\n",
      "[3.         0.92008544]\n",
      "[4.         0.70244775]\n",
      "[3.        0.8133987]\n",
      "[4.         0.59305839]\n",
      "[1.         0.48979008]\n",
      "[0.         0.76424835]\n",
      "[1.         0.51388585]\n",
      "[1.         0.74358847]\n",
      "[1.         0.73903266]\n",
      "[1.         0.85498894]\n",
      "[4.         0.70739251]\n",
      "[4.         0.77635094]\n",
      "[1.         0.84837191]\n",
      "[1.         0.66371071]\n",
      "[3.         0.81035101]\n",
      "[1.         0.63816245]\n",
      "[1.         0.84088247]\n",
      "[3.         0.65884414]\n",
      "[4.         0.77420069]\n",
      "[1.         0.75201643]\n",
      "[1.         0.75303622]\n",
      "[4.         0.81518806]\n",
      "[1.         0.72686716]\n",
      "[1.         0.75861997]\n",
      "[3.         0.66051443]\n",
      "[4.         0.73539751]\n",
      "[3.         0.64758647]\n",
      "[1.         0.54880939]\n",
      "[1.         0.70142212]\n",
      "[1.         0.84970559]\n",
      "[4.         0.73487319]\n",
      "[0.        0.8778316]\n",
      "[2.00000000e+00 6.88582235e-10]\n",
      "[4.         0.60425523]\n",
      "[0.         0.84099512]\n",
      "[1.         0.68915924]\n",
      "[1.         0.79517382]\n",
      "[1.         0.67405447]\n",
      "[1.         0.57052529]\n",
      "[1.         0.80623001]\n",
      "[1.        0.8378814]\n",
      "[0.         0.73356694]\n",
      "[1.         0.62825743]\n",
      "[0.        0.8207885]\n",
      "[0.         0.61161808]\n",
      "[0.         0.73665303]\n",
      "[3.         0.62507195]\n",
      "[1.         0.79984624]\n",
      "[1.         0.59943325]\n",
      "[3.         0.68232146]\n",
      "[4.        0.6952981]\n",
      "[1.         0.74409919]\n",
      "[3.       0.798868]\n",
      "[0.         0.75059608]\n",
      "[0.         0.75600845]\n",
      "[1.         0.69660058]\n",
      "[4.        0.5333607]\n",
      "[1.         0.83406107]\n",
      "[3.         0.77730114]\n",
      "[3.        0.8006163]\n",
      "[1.        0.8571992]\n",
      "[4.         0.68059944]\n",
      "[0.         0.69845787]\n",
      "[4.         0.63230808]\n",
      "[4.         0.66315798]\n",
      "[3.         0.82292299]\n",
      "[4.         0.69865941]\n",
      "[1.         0.58760756]\n",
      "[3.         0.77426414]\n",
      "[1.         0.80912226]\n",
      "[1.         0.73405603]\n",
      "[4.         0.49283085]\n",
      "[1.         0.76239849]\n",
      "[1.         0.66052408]\n",
      "[3.         0.75313142]\n",
      "[1.        0.7628981]\n",
      "[0.         0.72841219]\n",
      "[0.         0.77737791]\n",
      "[4.         0.59100464]\n",
      "[0.         0.78068244]\n",
      "[4.        0.6592158]\n",
      "[3.         0.70205926]\n",
      "[0.         0.61300492]\n",
      "[1.         0.71298781]\n",
      "[4.        0.7101028]\n",
      "[3.         0.79311044]\n",
      "[3.         0.71200227]\n",
      "[1.        0.7657061]\n",
      "[1.         0.64892663]\n",
      "[4.         0.70423275]\n",
      "[1.         0.73303637]\n",
      "[1.         0.48496573]\n",
      "[4.        0.6592077]\n",
      "[1.         0.79051272]\n",
      "[0.         0.67049176]\n",
      "[4.         0.74552581]\n",
      "[1.         0.72820601]\n",
      "[1.         0.63696542]\n",
      "[4.         0.39591712]\n",
      "[1.         0.73613209]\n",
      "[1.         0.68697326]\n",
      "[1.        0.6910258]\n",
      "[1.         0.69099652]\n",
      "[1.         0.88084091]\n",
      "[3.         0.73224101]\n",
      "[1.         0.81677017]\n",
      "[0.         0.61881383]\n",
      "[0.         0.76979755]\n",
      "[4.         0.79927449]\n",
      "[1.         0.88823733]\n",
      "[3.         0.84818215]\n",
      "[4.        0.7093827]\n",
      "[1.         0.56056254]\n",
      "[4.         0.76265343]\n",
      "[1.        0.6385369]\n",
      "[3.         0.84230297]\n",
      "[1.         0.79147281]\n",
      "[1.         0.67822624]\n",
      "[3.         0.62007738]\n",
      "[1.        0.6225628]\n",
      "[1.         0.66028449]\n",
      "[4.        0.5349242]\n",
      "[1.         0.64422308]\n",
      "[0.         0.76858616]\n",
      "[3.         0.60711992]\n",
      "[0.         0.73585006]\n",
      "[1.         0.70065705]\n",
      "[4.         0.38206967]\n",
      "[4.         0.54711998]\n",
      "[1.         0.79637959]\n",
      "[4.         0.78035644]\n",
      "[1.        0.8279303]\n",
      "[3.         0.61577787]\n",
      "[0.         0.82970872]\n",
      "[3.         0.82249033]\n",
      "[1.        0.7245098]\n",
      "[1.         0.83015838]\n",
      "[0.         0.69543322]\n",
      "[4.         0.60357769]\n",
      "[1.         0.89740278]\n",
      "[1.         0.61291962]\n",
      "[1.         0.67756034]\n",
      "[0.        0.8288942]\n",
      "[0.         0.67262745]\n",
      "[1.         0.88975498]\n",
      "[1.         0.72122035]\n",
      "[3.         0.79854074]\n",
      "[3.         0.87687307]\n",
      "[3.         0.73149762]\n",
      "[1.         0.69396722]\n",
      "[3.         0.74577194]\n",
      "[4.         0.56753038]\n",
      "[3.         0.68932067]\n",
      "[3.         0.86209792]\n",
      "[1.         0.62162266]\n",
      "[4.         0.84828088]\n",
      "[1.         0.68998845]\n",
      "[4.        0.8370562]\n",
      "[4.         0.71149324]\n",
      "[1.         0.63530087]\n",
      "[1.         0.72757921]\n",
      "[0.         0.75298797]\n",
      "[3.         0.58855483]\n",
      "[1.         0.73533672]\n",
      "[4.         0.68505954]\n",
      "[1.         0.69993439]\n",
      "[0.         0.67443361]\n",
      "[3.         0.65199464]\n",
      "[1.         0.69547961]\n",
      "[1.         0.71015023]\n",
      "[4.         0.38620033]\n",
      "[1.         0.64327612]\n",
      "[4.         0.58523723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.         0.82631628]\n",
      "[1.         0.74804773]\n",
      "[1.         0.75926844]\n",
      "[1.         0.75405798]\n",
      "[1.         0.80356704]\n",
      "[3.         0.70619447]\n",
      "[1.         0.58977148]\n",
      "[3.        0.7465948]\n",
      "[0.      0.32852]\n",
      "[1.        0.7787862]\n",
      "[1.         0.85414035]\n",
      "[4.         0.73105886]\n",
      "[4.         0.72869201]\n",
      "[1.         0.71354029]\n",
      "[3.         0.78559526]\n",
      "[0.         0.70826947]\n",
      "[3.        0.8158309]\n",
      "[1.         0.52503539]\n",
      "[1.         0.68855716]\n",
      "[1.         0.77073956]\n",
      "[1.         0.69108073]\n",
      "[4.         0.71614996]\n",
      "[0.         0.76586691]\n",
      "[3.         0.66678174]\n",
      "[0.         0.70475003]\n",
      "[1.         0.91863368]\n",
      "[0.         0.52928584]\n",
      "[0.        0.8157326]\n",
      "[1.         0.69580793]\n",
      "[4.         0.60480551]\n",
      "[1.         0.80958456]\n",
      "[3.       0.719728]\n",
      "[1.         0.80732477]\n",
      "[3.         0.51561688]\n",
      "[4.         0.47173478]\n",
      "[1.         0.59455319]\n",
      "[1.         0.73763674]\n",
      "[3.        0.6833216]\n",
      "[0.         0.85990928]\n",
      "[0.         0.86276148]\n",
      "[4.         0.74109328]\n",
      "[4.         0.58430558]\n",
      "[4.         0.78204565]\n",
      "[4.         0.67162135]\n",
      "[1.         0.81077454]\n",
      "[4.         0.72643105]\n",
      "[1.         0.68680758]\n",
      "[1.         0.79163568]\n",
      "[4.         0.85391407]\n",
      "[4.         0.45306603]\n",
      "[3.         0.82477166]\n",
      "[3.         0.76710019]\n",
      "[3.         0.65792397]\n",
      "[3.         0.84374332]\n",
      "[4.         0.65621562]\n",
      "[1.         0.52236686]\n",
      "[1.         0.79164004]\n",
      "[3.         0.87583858]\n",
      "[0.         0.77991983]\n",
      "[1.         0.74564631]\n",
      "[1.         0.78197647]\n",
      "[3.         0.77875389]\n",
      "[3.         0.66672162]\n",
      "[1.       0.727152]\n",
      "[4.        0.5079223]\n",
      "[1.         0.70396394]\n",
      "[1.         0.65465289]\n",
      "[0.        0.7214779]\n",
      "[3.         0.78169345]\n",
      "[0.         0.67272414]\n",
      "[3.         0.78689868]\n",
      "[0.         0.75477876]\n",
      "[0.        0.7815597]\n",
      "[4.         0.68883458]\n",
      "[4.         0.67639759]\n",
      "[1.         0.77619427]\n",
      "[4.         0.42436724]\n",
      "[0.         0.71720352]\n",
      "[1.         0.42805193]\n",
      "[3.         0.73920692]\n",
      "[4.         0.72641884]\n",
      "[4.         0.71738037]\n",
      "[1.         0.65360457]\n",
      "[4.         0.77466554]\n",
      "[4.         0.66837897]\n",
      "[4.         0.49177632]\n",
      "[4.        0.6843897]\n",
      "[0.         0.77125101]\n",
      "[3.        0.8169631]\n",
      "[1.         0.72726701]\n",
      "[3.         0.76105872]\n",
      "[3.         0.77781587]\n",
      "[1.         0.71213961]\n",
      "[1.         0.74505297]\n",
      "[1.         0.78604024]\n",
      "[4.         0.61586536]\n",
      "[3.         0.70239442]\n",
      "[0.         0.68522302]\n",
      "[3.         0.73729405]\n",
      "[1.         0.80606125]\n",
      "[0.         0.64441451]\n",
      "[1.         0.49983346]\n",
      "[1.         0.80093625]\n",
      "[1.         0.72128205]\n",
      "[3.         0.72303243]\n",
      "[0.        0.7790505]\n",
      "[3.         0.77067825]\n",
      "[1.         0.73009561]\n",
      "[1.         0.69155245]\n",
      "[0.         0.75271753]\n",
      "[1.         0.77401281]\n",
      "[1.         0.68442437]\n",
      "[1.         0.67119666]\n",
      "[1.         0.80275811]\n",
      "[4.         0.51629158]\n",
      "[4.         0.66468444]\n",
      "[1.         0.69111624]\n",
      "[0.         0.77209126]\n",
      "[3.         0.59936118]\n",
      "[1.         0.83204533]\n",
      "[1.         0.68129014]\n",
      "[1.         0.74181249]\n",
      "[3.         0.77842042]\n",
      "[3.         0.74526217]\n",
      "[4.         0.36549123]\n",
      "[1.         0.67595105]\n",
      "[3.         0.47375606]\n",
      "[4.         0.50350644]\n",
      "[1.         0.59015829]\n",
      "[1.         0.77577287]\n",
      "[3.         0.68715195]\n",
      "[0.         0.72165824]\n",
      "[4.         0.73583252]\n",
      "[0.         0.79496982]\n",
      "[1.         0.75282687]\n",
      "[3.         0.76135933]\n",
      "[0.         0.73095122]\n",
      "[4.         0.65603499]\n",
      "[1.         0.62063228]\n",
      "[1.         0.52680464]\n",
      "[1.         0.72508919]\n",
      "[3.         0.63389675]\n",
      "[3.         0.75335525]\n",
      "[1.         0.54724403]\n",
      "[1.         0.73511887]\n",
      "[4.         0.73151883]\n",
      "[0.         0.50832269]\n",
      "[4.        0.6349684]\n",
      "[0.         0.57714574]\n",
      "[4.         0.33245298]\n",
      "[0.         0.52054081]\n",
      "[3.         0.86735125]\n",
      "[4.         0.67960383]\n",
      "[1.         0.68950396]\n",
      "[1.         0.74576768]\n",
      "[0.        0.7209509]\n",
      "[1.         0.64646455]\n",
      "[0.         0.74385322]\n",
      "[3.        0.9250935]\n",
      "[3.         0.94762696]\n",
      "[1.         0.86522029]\n",
      "[1.         0.59794431]\n",
      "[0.         0.84987056]\n",
      "[4.         0.81767645]\n",
      "[3.         0.40336736]\n",
      "[1.         0.62020757]\n",
      "[1.         0.74930024]\n",
      "[4.         0.72984967]\n",
      "[4.         0.77372996]\n",
      "[1.         0.75223675]\n",
      "[1.         0.64364395]\n",
      "[3.       0.711577]\n",
      "[0.         0.62791707]\n",
      "[3.         0.70646812]\n",
      "[1.         0.63432263]\n",
      "[4.        0.7174518]\n",
      "[1.         0.64110437]\n",
      "[3.         0.74111626]\n",
      "[0.         0.73915846]\n",
      "[1.         0.85062672]\n",
      "[1.         0.65591036]\n",
      "[1.         0.77691856]\n",
      "[4.         0.65490892]\n",
      "[4.         0.51154912]\n",
      "[1.         0.56506809]\n",
      "[3.         0.48023513]\n",
      "[4.        0.5545566]\n",
      "[1.         0.61159473]\n",
      "[4.         0.60741322]\n",
      "[0.         0.66249745]\n",
      "[4.         0.53416985]\n",
      "[1.         0.85062562]\n",
      "[1.         0.64294718]\n",
      "[4.         0.65981758]\n",
      "[1.         0.70293018]\n",
      "[3.         0.75839941]\n",
      "[1.         0.92482697]\n",
      "[3.         0.76394361]\n",
      "[4.        0.7273139]\n",
      "[1.         0.91971015]\n",
      "[1.         0.86445605]\n",
      "[0.         0.71499143]\n",
      "[1.         0.84179317]\n",
      "[1.         0.67264755]\n",
      "[1.         0.80391526]\n",
      "[1.         0.71375747]\n",
      "[3.         0.62697667]\n",
      "[3.        0.8853302]\n",
      "[1.        0.7822465]\n",
      "[1.         0.60099514]\n",
      "[4.         0.66969655]\n",
      "[1.         0.70438016]\n",
      "[0.        0.7252016]\n",
      "[4.         0.72458499]\n",
      "[4.         0.55301047]\n",
      "[1.         0.85079714]\n",
      "[4.         0.76555091]\n",
      "[0.         0.52684441]\n",
      "[0.         0.67083744]\n",
      "[1.         0.78228006]\n",
      "[2.00000000e+00 4.76254254e-10]\n",
      "[1.         0.74851608]\n",
      "[4.      0.79199]\n",
      "[1.         0.83216763]\n",
      "[0.         0.62977735]\n",
      "[3.        0.5390742]\n",
      "[3.         0.74651888]\n",
      "[0.         0.62763224]\n",
      "[3.         0.80801443]\n",
      "[3.         0.72341496]\n",
      "[1.         0.68066559]\n",
      "[0.         0.62010404]\n",
      "[1.         0.62988133]\n",
      "[1.         0.77669452]\n",
      "[1.         0.91002411]\n",
      "[3.         0.59894517]\n",
      "[1.        0.8004801]\n",
      "[4.         0.48148817]\n",
      "[4.         0.64958064]\n",
      "[3.         0.37329971]\n",
      "[0.         0.78381535]\n",
      "[4.         0.50847659]\n",
      "[4.         0.65446288]\n",
      "[3.         0.66668909]\n",
      "[3.         0.76490676]\n",
      "[3.         0.86250354]\n",
      "[4.         0.75587499]\n",
      "[3.         0.62252691]\n",
      "[1.         0.82172113]\n",
      "[0.         0.72089089]\n",
      "[1.         0.86248579]\n",
      "[4.         0.54477653]\n",
      "[4.         0.66811114]\n",
      "[3.         0.76419194]\n",
      "[0.         0.80180426]\n",
      "[1.         0.82392132]\n",
      "[3.       0.782368]\n",
      "[0.         0.70959682]\n",
      "[1.         0.59849855]\n",
      "[1.         0.84804114]\n",
      "[1.         0.78025891]\n",
      "[1.         0.70416691]\n",
      "[3.         0.81726981]\n",
      "[1.         0.65528886]\n",
      "[1.         0.60241684]\n",
      "[4.        0.7370506]\n",
      "[1.         0.91459818]\n",
      "[4.         0.74210172]\n",
      "[4.         0.72246017]\n",
      "[0.         0.63758917]\n",
      "[4.         0.77487584]\n",
      "[4.         0.69007166]\n",
      "[1.         0.70278914]\n",
      "[4.         0.85998238]\n",
      "[3.         0.69995877]\n",
      "[3.        0.7965071]\n",
      "[3.         0.71728896]\n",
      "[4.         0.68417817]\n",
      "[0.         0.67125678]\n",
      "[3.         0.46630272]\n",
      "[3.         0.86307967]\n",
      "[1.         0.58429153]\n",
      "[3.         0.76004023]\n",
      "[0.         0.57711685]\n",
      "[1.        0.8523147]\n",
      "[4.         0.52667582]\n",
      "[1.         0.78916526]\n",
      "[1.         0.83915023]\n",
      "[1.        0.6582104]\n",
      "[3.         0.66444914]\n",
      "[4.        0.5426603]\n",
      "[3.         0.60099547]\n",
      "[4.         0.61260282]\n",
      "[4.         0.80759889]\n",
      "[4.        0.7306205]\n",
      "[4.         0.81800529]\n",
      "[1.         0.64180519]\n",
      "[0.         0.76425339]\n",
      "[1.         0.60732635]\n",
      "[0.         0.85925972]\n",
      "[1.         0.65735003]\n",
      "[0.         0.63832145]\n",
      "[4.         0.68486075]\n",
      "[1.         0.83562938]\n",
      "[3.         0.88325127]\n",
      "[3.         0.66699335]\n",
      "[3.        0.7981822]\n",
      "[1.         0.70094118]\n",
      "[0.         0.64986378]\n",
      "[4.         0.75059269]\n",
      "[3.         0.75988878]\n",
      "[1.         0.87151717]\n",
      "[0.         0.74096921]\n",
      "[1.         0.76806015]\n",
      "[3.         0.76413333]\n",
      "[1.         0.69867724]\n",
      "[4.         0.74862033]\n",
      "[1.         0.56763482]\n",
      "[1.       0.890356]\n",
      "[1.        0.6372871]\n",
      "[1.         0.60883829]\n",
      "[1.         0.58421736]\n",
      "[4.         0.69948314]\n",
      "[0.         0.70128174]\n",
      "[1.         0.65538751]\n",
      "[4.         0.61976892]\n",
      "[4.         0.59139462]\n",
      "[4.         0.63362353]\n",
      "[1.         0.67357546]\n",
      "[1.         0.73189803]\n",
      "[4.         0.66359024]\n",
      "[0.         0.76078897]\n",
      "[1.         0.79870613]\n",
      "[1.         0.71532349]\n",
      "[1.        0.6845241]\n",
      "[3.         0.66693057]\n",
      "[1.         0.76666519]\n",
      "[0.         0.69358492]\n",
      "[1.         0.70435813]\n",
      "[1.         0.72992674]\n",
      "[0.         0.86119351]\n",
      "[1.         0.67998756]\n",
      "[1.         0.84313131]\n",
      "[3.         0.50059739]\n",
      "[1.         0.64871406]\n",
      "[2.00000000e+00 2.42274087e-10]\n",
      "[0.         0.65155914]\n",
      "[0.         0.75607094]\n",
      "[3.         0.45705406]\n",
      "[1.         0.57266876]\n",
      "[1.         0.87108518]\n",
      "[1.         0.75166482]\n",
      "[3.         0.53844498]\n",
      "[3.         0.67556602]\n",
      "[1.         0.74407229]\n",
      "[0.         0.69095587]\n",
      "[1.         0.75340208]\n",
      "[0.         0.77327631]\n",
      "[1.        0.6095561]\n",
      "[0.         0.76735501]\n",
      "[1.         0.66723644]\n",
      "[1.         0.88739803]\n",
      "[1.         0.73360364]\n",
      "[0.         0.81110961]\n",
      "[0.        0.5879272]\n",
      "[1.         0.77969441]\n",
      "[1.         0.62817339]\n",
      "[1.         0.75918105]\n",
      "[4.         0.61615644]\n",
      "[3.         0.80893539]\n",
      "[1.         0.75989918]\n",
      "[1.         0.82430605]\n",
      "[4.         0.82123139]\n",
      "[1.         0.65127898]\n",
      "[4.        0.4930377]\n",
      "[1.         0.62643684]\n",
      "[1.         0.68189342]\n",
      "[0.         0.61698428]\n",
      "[1.         0.58852565]\n",
      "[0.         0.75602265]\n",
      "[1.        0.7962677]\n",
      "[4.         0.80153605]\n",
      "[1.         0.79769445]\n",
      "[4.         0.70382278]\n",
      "[0.         0.70633657]\n",
      "[3.         0.77942814]\n",
      "[3.         0.74506763]\n",
      "[1.         0.63567578]\n",
      "[1.        0.5763653]\n",
      "[4.         0.67732047]\n",
      "[1.         0.87353024]\n",
      "[1.       0.736239]\n",
      "[0.         0.76952955]\n",
      "[4.         0.90734092]\n",
      "[3.        0.8095033]\n",
      "[1.         0.85236577]\n",
      "[1.         0.81366242]\n",
      "[3.        0.8853302]\n",
      "[1.         0.58537119]\n",
      "[1.         0.78613287]\n",
      "[3.       0.898861]\n",
      "[1.         0.61195047]\n",
      "[1.         0.54938691]\n",
      "[1.         0.87725463]\n",
      "[1.         0.61170936]\n",
      "[4.         0.57957496]\n",
      "[4.         0.75375663]\n",
      "[1.         0.90514483]\n",
      "[0.         0.66603483]\n",
      "[1.         0.50700192]\n",
      "[3.         0.85387542]\n",
      "[1.        0.7509101]\n",
      "[0.        0.7495384]\n",
      "[1.         0.52397223]\n",
      "[1.         0.65732592]\n",
      "[1.         0.62507515]\n",
      "[0.         0.55484013]\n",
      "[1.         0.85484212]\n",
      "[3.         0.72403144]\n",
      "[1.         0.59486383]\n",
      "[0.         0.38519258]\n",
      "[1.         0.84206448]\n",
      "[4.         0.67141106]\n",
      "[1.         0.58652315]\n",
      "[0.         0.65694988]\n",
      "[0.         0.81641202]\n",
      "[1.        0.7680872]\n",
      "[4.         0.55410661]\n",
      "[1.         0.75007051]\n",
      "[4.        0.7931577]\n",
      "[1.         0.52416441]\n",
      "[1.         0.89132756]\n",
      "[1.         0.84577975]\n",
      "[1.         0.68413582]\n",
      "[4.         0.62798849]\n",
      "[3.         0.78565925]\n",
      "[4.         0.74228754]\n",
      "[1.         0.89463042]\n",
      "[3.         0.72130073]\n",
      "[1.         0.58329587]\n",
      "[0.         0.70329599]\n",
      "[1.         0.75377645]\n",
      "[1.         0.72813762]\n",
      "[0.        0.8182183]\n",
      "[3.         0.61187044]\n",
      "[1.         0.83499724]\n",
      "[1.         0.84925224]\n",
      "[3.         0.81574818]\n",
      "[3.         0.67795531]\n",
      "[3.         0.74229951]\n",
      "[4.         0.63781773]\n",
      "[3.         0.58348683]\n",
      "[0.        0.6869171]\n",
      "[2.        0.6324405]\n",
      "[0.         0.77547829]\n",
      "[0.         0.50326514]\n",
      "[1.        0.8430048]\n",
      "[1.         0.51081934]\n",
      "[1.         0.82519367]\n",
      "[4.         0.68451378]\n",
      "[1.        0.6213714]\n",
      "[3.         0.78144494]\n",
      "[4.         0.51712517]\n",
      "[3.         0.59769289]\n",
      "[0.         0.76062368]\n",
      "[1.         0.71236862]\n",
      "[0.         0.67648428]\n",
      "[1.         0.54425642]\n",
      "[3.         0.72847224]\n",
      "[3.         0.67367358]\n",
      "[3.         0.73247847]\n",
      "[4.         0.67898576]\n",
      "[1.         0.72872908]\n",
      "[0.         0.61998893]\n",
      "[4.         0.58836237]\n",
      "[1.         0.86027557]\n",
      "[0.         0.81950442]\n",
      "[0.         0.78058362]\n",
      "[1.         0.82265467]\n",
      "[0.         0.78399556]\n",
      "[1.         0.59825629]\n",
      "[4.         0.52301143]\n",
      "[0.         0.65496233]\n",
      "[4.         0.61794417]\n",
      "[1.        0.9004361]\n",
      "[3.         0.63402039]\n",
      "[1.         0.62924206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.         0.75774922]\n",
      "[0.       0.657274]\n",
      "[4.         0.83406286]\n",
      "[0.         0.72099712]\n",
      "[1.         0.51445949]\n",
      "[4.         0.68899221]\n",
      "[3.         0.69171634]\n",
      "[1.         0.72343917]\n",
      "[4.         0.79304174]\n",
      "[1.         0.85370561]\n",
      "[1.         0.46720101]\n",
      "[4.        0.6263426]\n",
      "[1.         0.71797834]\n",
      "[1.         0.69354441]\n",
      "[3.         0.41683862]\n",
      "[4.       0.632457]\n",
      "[1.         0.67637952]\n",
      "[0.         0.54905916]\n",
      "[1.         0.59255565]\n",
      "[1.         0.85173202]\n",
      "[1.         0.73473214]\n",
      "[4.         0.76044292]\n",
      "[1.         0.40306224]\n",
      "[1.         0.84160994]\n",
      "[1.         0.79645562]\n",
      "[1.         0.67833061]\n",
      "[1.         0.63346954]\n",
      "[1.         0.57290147]\n",
      "[4.         0.64151364]\n",
      "[0.         0.52616459]\n",
      "[0.         0.62543599]\n",
      "[3.        0.6427458]\n",
      "[0.        0.8084139]\n",
      "[1.         0.70122181]\n",
      "[3.         0.63512528]\n",
      "[1.         0.82205084]\n",
      "[3.         0.97066665]\n",
      "[0.         0.71245832]\n",
      "[3.         0.64215257]\n",
      "[4.         0.80439315]\n",
      "[0.         0.53283599]\n",
      "[1.         0.53018978]\n",
      "[0.         0.53286508]\n",
      "[3.         0.85247133]\n",
      "[3.         0.75602129]\n",
      "[1.         0.65890589]\n",
      "[0.         0.70784562]\n",
      "[3.         0.74181018]\n",
      "[1.         0.69525254]\n",
      "[0.        0.7853038]\n",
      "[4.         0.71981527]\n",
      "[0.         0.67446292]\n",
      "[1.         0.72755039]\n",
      "[3.         0.70326846]\n",
      "[3.         0.74521344]\n",
      "[1.         0.91611721]\n",
      "[3.         0.74148533]\n",
      "[0.         0.70101459]\n",
      "[3.         0.73234578]\n",
      "[0.         0.76126228]\n",
      "[3.         0.70729535]\n",
      "[4.         0.67492366]\n",
      "[3.         0.63939205]\n",
      "[3.       0.811277]\n",
      "[1.         0.64570638]\n",
      "[4.         0.97694905]\n",
      "[1.         0.71411277]\n",
      "[3.        0.8534162]\n",
      "[1.         0.66201069]\n",
      "[1.         0.67320324]\n",
      "[4.         0.80467109]\n",
      "[4.         0.81293093]\n",
      "[1.         0.61309233]\n",
      "[1.         0.74345164]\n",
      "[1.         0.73530472]\n",
      "[1.         0.69287431]\n",
      "[1.         0.67640367]\n",
      "[1.         0.82128934]\n",
      "[3.         0.69136459]\n",
      "[4.         0.81419453]\n",
      "[4.         0.85447072]\n",
      "[0.         0.64255123]\n",
      "[4.         0.55519448]\n",
      "[3.         0.74905449]\n",
      "[0.         0.71444193]\n",
      "[1.         0.74275935]\n",
      "[4.         0.67420815]\n",
      "[0.         0.62565345]\n",
      "[1.        0.4738087]\n",
      "[3.         0.83188961]\n",
      "[4.         0.77699534]\n",
      "[3.         0.82316253]\n",
      "[3.         0.74774412]\n",
      "[0.         0.82459851]\n",
      "[4.         0.80054048]\n",
      "[4.         0.71081072]\n",
      "[4.        0.6543205]\n",
      "[1.        0.7316502]\n",
      "[3.        0.6673318]\n",
      "[1.         0.73525561]\n",
      "[0.         0.62952698]\n",
      "[3.         0.81390331]\n",
      "[3.         0.69915157]\n",
      "[3.         0.75551473]\n",
      "[0.         0.70430884]\n",
      "[1.         0.66578652]\n",
      "[1.         0.67456625]\n",
      "[3.         0.67511891]\n",
      "[4.         0.82590829]\n",
      "[3.         0.68238164]\n",
      "[1.       0.757233]\n",
      "[0.         0.76049895]\n",
      "[1.         0.82260911]\n",
      "[0.         0.71693335]\n",
      "[0.         0.81932843]\n",
      "[1.         0.78364096]\n",
      "[1.         0.66857529]\n",
      "[0.         0.66407739]\n",
      "[4.         0.50768108]\n",
      "[1.         0.54771305]\n",
      "[4.         0.57625388]\n",
      "[3.         0.62082853]\n",
      "[4.         0.53623861]\n",
      "[4.         0.51767157]\n",
      "[1.         0.59288219]\n",
      "[4.         0.54906627]\n",
      "[0.        0.6917447]\n",
      "[4.         0.75525208]\n",
      "[0.         0.66209397]\n",
      "[1.         0.68347264]\n",
      "[1.        0.8918728]\n",
      "[1.         0.74574475]\n",
      "[1.         0.68566589]\n",
      "[1.         0.76574924]\n",
      "[0.         0.87354221]\n",
      "[1.         0.45518916]\n",
      "[3.         0.73902769]\n",
      "[1.         0.56772549]\n",
      "[4.        0.5971676]\n",
      "[4.        0.5486331]\n",
      "[4.         0.75638201]\n",
      "[3.         0.36768134]\n",
      "[0.         0.72020545]\n",
      "[1.         0.92309952]\n",
      "[4.         0.53597021]\n",
      "[1.         0.66341162]\n",
      "[4.         0.62864891]\n",
      "[3.         0.60260925]\n",
      "[3.        0.7936693]\n",
      "[1.         0.69428354]\n",
      "[3.         0.67967304]\n",
      "[1.         0.54076874]\n",
      "[1.         0.56660452]\n",
      "[0.         0.73561636]\n",
      "[0.         0.64020234]\n",
      "[0.         0.67226112]\n",
      "[1.         0.75643384]\n",
      "[4.         0.57424405]\n",
      "[3.         0.83949355]\n",
      "[1.         0.76870917]\n",
      "[0.         0.66408993]\n",
      "[1.         0.68645596]\n",
      "[1.         0.53050674]\n",
      "[4.         0.51781122]\n",
      "[1.         0.86558608]\n",
      "[1.         0.80102947]\n",
      "[4.         0.61442201]\n",
      "[1.         0.70468267]\n",
      "[1.         0.78227518]\n",
      "[1.         0.66524478]\n",
      "[0.         0.78694383]\n",
      "[1.         0.82028379]\n",
      "[1.         0.84413568]\n",
      "[4.        0.6691804]\n",
      "[4.         0.66874262]\n",
      "[4.         0.63099224]\n",
      "[4.         0.68266727]\n",
      "[4.         0.76043123]\n",
      "[1.         0.56013528]\n",
      "[3.         0.84112409]\n",
      "[4.         0.62669441]\n",
      "[1.         0.71346209]\n",
      "[1.         0.67377272]\n",
      "[0.         0.74793457]\n",
      "[4.         0.55457811]\n",
      "[1.         0.67725949]\n",
      "[0.         0.68371277]\n",
      "[0.        0.3537932]\n",
      "[0.         0.78452889]\n",
      "[4.         0.62373578]\n",
      "[3.         0.69939945]\n",
      "[4.         0.64270607]\n",
      "[1.         0.84571779]\n",
      "[0.         0.72853438]\n",
      "[1.         0.80252861]\n",
      "[1.         0.80574258]\n",
      "[4.         0.68839186]\n",
      "[1.         0.72382436]\n",
      "[4.         0.68876743]\n",
      "[1.         0.72509553]\n",
      "[0.         0.81316503]\n",
      "[3.         0.75423783]\n",
      "[1.         0.82147479]\n",
      "[1.         0.66709983]\n",
      "[0.         0.65904857]\n",
      "[1.         0.76558692]\n",
      "[1.         0.48695264]\n",
      "[4.         0.81604011]\n",
      "[4.         0.65400546]\n",
      "[3.         0.62802976]\n",
      "[1.         0.82565701]\n",
      "[4.         0.71326299]\n",
      "[4.         0.75769357]\n",
      "[1.         0.83250463]\n",
      "[0.         0.82088743]\n",
      "[4.        0.5489343]\n",
      "[1.         0.89028658]\n",
      "[4.         0.56555196]\n",
      "[1.         0.79086134]\n",
      "[1.        0.6811787]\n",
      "[4.         0.67938794]\n",
      "[0.         0.74752302]\n",
      "[0.         0.62512093]\n",
      "[1.         0.64876186]\n",
      "[4.         0.56731306]\n",
      "[0.         0.63818014]\n",
      "[4.         0.64108473]\n",
      "[0.        0.5827371]\n",
      "[0.         0.56104774]\n",
      "[3.         0.79191977]\n",
      "[4.        0.7731616]\n",
      "[1.         0.57117758]\n",
      "[0.         0.52539905]\n",
      "[3.         0.76707528]\n",
      "[4.         0.74396606]\n",
      "[3.         0.74470575]\n",
      "[1.         0.81208044]\n",
      "[1.         0.71038082]\n",
      "[3.         0.78865689]\n",
      "[0.         0.67346516]\n",
      "[1.        0.7882045]\n",
      "[0.         0.91908654]\n",
      "[1.         0.82699777]\n",
      "[1.         0.79613628]\n",
      "[4.       0.877959]\n",
      "[4.         0.68871322]\n",
      "[1.       0.669512]\n",
      "[0.         0.55044183]\n",
      "[0.         0.45558429]\n",
      "[1.         0.61111593]\n",
      "[0.         0.66015039]\n",
      "[0.         0.62072603]\n",
      "[1.         0.71944017]\n",
      "[4.         0.75919327]\n",
      "[1.         0.61179955]\n",
      "[0.         0.70242138]\n",
      "[0.         0.69734874]\n",
      "[0.         0.56320895]\n",
      "[3.         0.80739466]\n",
      "[0.         0.73206191]\n",
      "[1.         0.66868762]\n",
      "[0.         0.81994226]\n",
      "[1.         0.36341886]\n",
      "[0.         0.68284315]\n",
      "[0.         0.62584327]\n",
      "[1.         0.67316523]\n",
      "[1.         0.61918526]\n",
      "[1.         0.72003464]\n",
      "[0.         0.77356061]\n",
      "[4.         0.69839601]\n",
      "[3.         0.77197763]\n",
      "[1.        0.8957524]\n",
      "[0.         0.66821928]\n",
      "[1.         0.36079702]\n",
      "[4.         0.86825501]\n",
      "[4.         0.61170524]\n",
      "[1.         0.68063532]\n",
      "[1.         0.65426849]\n",
      "[3.        0.7394188]\n",
      "[1.         0.84257148]\n",
      "[0.         0.82703061]\n",
      "[4.         0.66336477]\n",
      "[1.         0.67106052]\n",
      "[1.         0.84266424]\n",
      "[4.         0.88134229]\n",
      "[4.         0.65150755]\n",
      "[1.         0.73725345]\n",
      "[0.         0.66919609]\n",
      "[0.         0.84465259]\n",
      "[1.         0.78424507]\n",
      "[3.         0.87047073]\n",
      "[4.         0.35559857]\n",
      "[4.         0.71209181]\n",
      "[0.         0.76299386]\n",
      "[4.         0.68549218]\n",
      "[1.         0.79633652]\n",
      "[1.         0.78994829]\n",
      "[3.         0.70930226]\n",
      "[4.        0.6865122]\n",
      "[1.         0.79611283]\n",
      "[1.         0.90336327]\n",
      "[4.         0.77694786]\n",
      "[3.         0.74756832]\n",
      "[4.         0.89868353]\n",
      "[3.         0.62718332]\n",
      "[1.         0.64966377]\n",
      "[3.         0.75996594]\n",
      "[4.         0.54273759]\n",
      "[1.         0.71906803]\n",
      "[4.         0.59815007]\n",
      "[0.         0.73060621]\n",
      "[1.         0.69856799]\n",
      "[1.         0.57295408]\n",
      "[0.         0.78729486]\n",
      "[4.        0.8863718]\n",
      "[1.         0.74132697]\n",
      "[4.         0.49811686]\n",
      "[4.         0.78480541]\n",
      "[4.         0.80129281]\n",
      "[0.         0.69388616]\n",
      "[3.         0.67695122]\n",
      "[1.         0.79944634]\n",
      "[0.         0.77634053]\n",
      "[4.         0.65361527]\n",
      "[0.         0.74526169]\n",
      "[1.         0.81582912]\n",
      "[4.         0.69478326]\n",
      "[1.         0.74794886]\n",
      "[3.         0.73072501]\n",
      "[1.         0.82961173]\n",
      "[1.         0.62386355]\n",
      "[1.         0.64190092]\n",
      "[0.         0.63973434]\n",
      "[3.         0.86229976]\n",
      "[1.         0.84790024]\n",
      "[3.         0.73002174]\n",
      "[0.         0.73443032]\n",
      "[1.        0.8049051]\n",
      "[4.        0.7239961]\n",
      "[0.         0.86846168]\n",
      "[4.         0.88453547]\n",
      "[1.         0.63146361]\n",
      "[0.         0.66336287]\n",
      "[4.        0.6965591]\n",
      "[3.         0.58869646]\n",
      "[3.         0.66115384]\n",
      "[3.         0.83695315]\n",
      "[0.         0.67327794]\n",
      "[1.         0.67143646]\n",
      "[1.         0.79933899]\n",
      "[4.         0.64305244]\n",
      "[0.         0.71478073]\n",
      "[4.         0.77557458]\n",
      "[0.         0.48310292]\n",
      "[4.       0.573303]\n",
      "[3.         0.89147077]\n",
      "[3.         0.70517421]\n",
      "[4.         0.67279246]\n",
      "[3.         0.76083269]\n",
      "[0.         0.69037985]\n",
      "[1.         0.84923317]\n",
      "[1.         0.82944396]\n",
      "[1.         0.83243387]\n",
      "[1.         0.81251277]\n",
      "[3.         0.84405241]\n",
      "[4.       0.766858]\n",
      "[4.         0.84581536]\n",
      "[4.         0.70249981]\n",
      "[1.         0.66738383]\n",
      "[1.         0.79035698]\n",
      "[3.         0.44436336]\n",
      "[1.         0.68761751]\n",
      "[1.         0.77403579]\n",
      "[1.         0.61060667]\n",
      "[3.         0.73533996]\n",
      "[0.         0.78827633]\n",
      "[3.         0.78470366]\n",
      "[1.         0.86593116]\n",
      "[1.         0.49106527]\n",
      "[0.         0.74229442]\n",
      "[4.         0.75455695]\n",
      "[1.         0.61532543]\n",
      "[3.         0.71083461]\n",
      "[3.         0.85803191]\n",
      "[0.         0.80261247]\n",
      "[0.         0.78977168]\n",
      "[0.         0.39706675]\n",
      "[1.         0.71317028]\n",
      "[3.        0.8158675]\n",
      "[1.         0.90993312]\n",
      "[0.         0.66853515]\n",
      "[1.         0.58593628]\n",
      "[3.         0.86099683]\n",
      "[0.         0.75009127]\n",
      "[0.         0.80236963]\n",
      "[0.         0.84247373]\n",
      "[1.         0.68158237]\n",
      "[3.        0.7775114]\n",
      "[1.         0.75399674]\n",
      "[4.         0.71699171]\n",
      "[4.         0.57922676]\n",
      "[1.         0.80861323]\n",
      "[0.         0.75658665]\n",
      "[3.         0.75981853]\n",
      "[4.         0.46875766]\n",
      "[0.         0.23845425]\n",
      "[4.         0.83825659]\n",
      "[0.         0.58178727]\n",
      "[0.         0.73342591]\n",
      "[4.         0.63739789]\n",
      "[3.        0.6229411]\n",
      "[1.         0.88445071]\n",
      "[4.         0.87143059]\n",
      "[4.         0.49307186]\n",
      "[1.         0.81002123]\n",
      "[1.         0.60881608]\n",
      "[4.         0.61020274]\n",
      "[1.        0.7852355]\n",
      "[1.         0.67466725]\n",
      "[3.         0.65670951]\n",
      "[1.         0.53312968]\n",
      "[0.         0.94596569]\n",
      "[3.         0.72426433]\n",
      "[0.         0.70800621]\n",
      "[0.         0.73027478]\n",
      "[4.         0.66319465]\n",
      "[0.         0.83149584]\n",
      "[1.         0.77530841]\n",
      "[1.         0.79418187]\n",
      "[3.         0.63307233]\n",
      "[1.         0.81858565]\n",
      "[3.         0.77867541]\n",
      "[1.         0.88242211]\n",
      "[4.         0.52737959]\n",
      "[1.         0.75459661]\n",
      "[3.         0.87047451]\n",
      "[3.         0.76413738]\n",
      "[1.         0.73273153]\n",
      "[1.        0.5514645]\n",
      "[4.         0.65358091]\n",
      "[4.         0.81161092]\n",
      "[1.         0.75485678]\n",
      "[1.         0.54923969]\n",
      "[0.         0.85590252]\n",
      "[1.        0.8250158]\n",
      "[0.         0.79045288]\n",
      "[3.         0.89881125]\n",
      "[0.         0.83813364]\n",
      "[0.        0.6916686]\n",
      "[1.        0.7117932]\n",
      "[3.         0.68636773]\n",
      "[1.         0.72570585]\n",
      "[0.         0.57869198]\n",
      "[1.         0.76164048]\n",
      "[4.         0.68759188]\n",
      "[4.         0.60132986]\n",
      "[1.         0.53190917]\n",
      "[4.         0.79299019]\n",
      "[3.         0.67502488]\n",
      "[0.         0.77192441]\n",
      "[0.         0.75803152]\n",
      "[0.         0.86491952]\n",
      "[1.         0.76936628]\n",
      "[1.         0.62071814]\n",
      "[1.         0.77982701]\n",
      "[1.         0.57627325]\n",
      "[0.         0.85865693]\n",
      "[1.         0.87032087]\n",
      "[3.         0.61710556]\n",
      "[0.         0.75124836]\n",
      "[3.        0.6927887]\n",
      "[3.         0.80467229]\n",
      "[3.         0.69193909]\n",
      "[1.         0.74942837]\n",
      "[4.         0.69131529]\n",
      "[1.         0.66263172]\n",
      "[3.         0.52585245]\n",
      "[4.         0.61341193]\n",
      "[4.         0.66706541]\n",
      "[3.         0.80696212]\n",
      "[3.         0.70843173]\n",
      "[0.         0.67312302]\n",
      "[4.       0.751945]\n",
      "[3.         0.74808785]\n",
      "[4.         0.78862837]\n",
      "[4.         0.49111858]\n",
      "[4.         0.72100205]\n",
      "[1.         0.69344315]\n",
      "[3.         0.66281608]\n",
      "[4.         0.70712687]\n",
      "[1.         0.61388191]\n",
      "[1.         0.86694372]\n",
      "[1.         0.70188015]\n",
      "[4.        0.6958114]\n",
      "[3.         0.69011566]\n",
      "[1.        0.8091201]\n",
      "[1.         0.62929944]\n",
      "[4.         0.36672624]\n",
      "[1.         0.75220749]\n",
      "[1.         0.69264102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.62969438]\n",
      "[4.         0.63004747]\n",
      "[1.         0.63264951]\n",
      "[0.         0.67587538]\n",
      "[4.         0.74286001]\n",
      "[1.         0.57916203]\n",
      "[1.         0.75782585]\n",
      "[1.         0.75907557]\n",
      "[1.         0.63823414]\n",
      "[4.        0.6159509]\n",
      "[3.         0.71530381]\n",
      "[4.         0.46950203]\n",
      "[0.         0.78693325]\n",
      "[0.         0.76982804]\n",
      "[0.         0.79150108]\n",
      "[1.         0.83192633]\n",
      "[1.         0.76838773]\n",
      "[4.         0.32822224]\n",
      "[1.        0.7081892]\n",
      "[1.         0.64064951]\n",
      "[3.         0.74917852]\n",
      "[1.         0.82321862]\n",
      "[4.         0.50124344]\n",
      "[1.         0.76634852]\n",
      "[4.         0.68501376]\n",
      "[0.         0.71849469]\n",
      "[1.         0.51570901]\n",
      "[4.         0.79334292]\n",
      "[4.         0.77435472]\n",
      "[4.         0.66081388]\n",
      "[1.        0.5698628]\n",
      "[4.         0.47388915]\n",
      "[3.         0.79372057]\n",
      "[1.         0.76557932]\n",
      "[1.         0.70233549]\n",
      "[3.         0.70891704]\n",
      "[4.         0.71002409]\n",
      "[3.         0.65409389]\n",
      "[1.         0.63937001]\n",
      "[4.         0.66447999]\n",
      "[0.         0.58586692]\n",
      "[1.         0.65340253]\n",
      "[1.         0.78350003]\n",
      "[1.        0.8176278]\n",
      "[1.         0.47568654]\n",
      "[3.         0.78274175]\n",
      "[4.         0.70617441]\n",
      "[4.         0.67976251]\n",
      "[4.         0.44944479]\n",
      "[1.         0.80344188]\n",
      "[1.         0.78588324]\n",
      "[3.         0.83768088]\n",
      "[1.         0.90898848]\n",
      "[4.         0.82496403]\n",
      "[1.         0.55507927]\n",
      "[1.         0.65610489]\n",
      "[1.         0.72220308]\n",
      "[1.         0.71614644]\n",
      "[1.         0.67810732]\n",
      "[3.         0.55364673]\n",
      "[1.         0.79017271]\n",
      "[3.         0.62138139]\n",
      "[4.         0.64711169]\n",
      "[1.         0.65673483]\n",
      "[1.         0.77566357]\n",
      "[4.         0.50948334]\n",
      "[0.         0.51932039]\n",
      "[4.         0.34749274]\n",
      "[1.         0.76625208]\n",
      "[1.         0.89745198]\n",
      "[1.         0.86269927]\n",
      "[0.         0.69307058]\n",
      "[3.         0.59186738]\n",
      "[1.         0.75935851]\n",
      "[1.         0.72249416]\n",
      "[3.         0.59069149]\n",
      "[1.         0.71011077]\n",
      "[1.         0.53541935]\n",
      "[1.         0.68997616]\n",
      "[1.         0.87319845]\n",
      "[1.        0.7307336]\n",
      "[0.         0.73883339]\n",
      "[0.        0.8215252]\n",
      "[1.         0.53241652]\n",
      "[4.         0.66874235]\n",
      "[4.         0.86964786]\n",
      "[1.         0.74082937]\n",
      "[3.         0.85860626]\n",
      "[4.         0.61243269]\n",
      "[1.         0.59749087]\n",
      "[1.         0.74185335]\n",
      "[4.         0.84869193]\n",
      "[1.         0.52003661]\n",
      "[4.         0.56156555]\n",
      "[1.         0.66218005]\n",
      "[3.         0.75535118]\n",
      "[4.         0.82015999]\n",
      "[1.        0.7631462]\n",
      "[4.         0.67030408]\n",
      "[1.         0.44587384]\n",
      "[1.         0.65402942]\n",
      "[1.         0.81088737]\n",
      "[3.        0.6754157]\n",
      "[4.         0.82323473]\n",
      "[4.         0.71256714]\n",
      "[1.         0.57484155]\n",
      "[1.         0.83896046]\n",
      "[1.         0.57453204]\n",
      "[4.         0.72064996]\n",
      "[4.         0.69235776]\n",
      "[3.       0.709121]\n",
      "[4.         0.64302888]\n",
      "[1.         0.61945723]\n",
      "[1.         0.79275722]\n",
      "[4.         0.68206717]\n",
      "[3.         0.58415806]\n",
      "[0.         0.85949544]\n",
      "[4.         0.66230322]\n",
      "[1.         0.77124767]\n",
      "[0.         0.59204057]\n",
      "[4.         0.76131135]\n",
      "[1.         0.81606344]\n",
      "[1.         0.71662824]\n",
      "[1.         0.62243601]\n",
      "[1.         0.76210167]\n",
      "[3.         0.81892345]\n",
      "[1.         0.79011665]\n",
      "[1.         0.72263961]\n",
      "[1.         0.71637143]\n",
      "[4.        0.9071653]\n",
      "[1.         0.74365623]\n",
      "[0.         0.78082943]\n",
      "[1.         0.80906574]\n",
      "[4.         0.78997255]\n",
      "[4.         0.67325137]\n",
      "[4.         0.68871322]\n",
      "[1.         0.82141673]\n",
      "[3.         0.77194866]\n",
      "[1.        0.6688509]\n",
      "[0.         0.68784549]\n",
      "[0.         0.83776869]\n",
      "[1.         0.65564069]\n",
      "[3.         0.88910931]\n",
      "[1.        0.6056206]\n",
      "[4.         0.58670469]\n",
      "[0.        0.4854474]\n",
      "[4.         0.72226666]\n",
      "[1.         0.82126062]\n",
      "[0.         0.70919997]\n",
      "[1.         0.74171547]\n",
      "[1.         0.87868672]\n",
      "[4.         0.81125812]\n",
      "[3.         0.73983845]\n",
      "[3.         0.71322275]\n",
      "[1.        0.6794962]\n",
      "[1.         0.71767624]\n",
      "[3.         0.76948841]\n",
      "[4.         0.68115573]\n",
      "[0.         0.68259837]\n",
      "[1.         0.80835262]\n",
      "[4.        0.8863679]\n",
      "[1.         0.72143731]\n",
      "[1.         0.57701039]\n",
      "[1.         0.77672929]\n",
      "[1.         0.88314088]\n",
      "[1.         0.65070439]\n",
      "[0.         0.87760006]\n",
      "[4.         0.57062348]\n",
      "[3.         0.89816437]\n",
      "[4.         0.82138079]\n",
      "[3.         0.65336224]\n",
      "[1.         0.60264815]\n",
      "[0.         0.70254834]\n",
      "[1.         0.45724998]\n",
      "[0.         0.46205813]\n",
      "[1.         0.45589535]\n",
      "[0.         0.77155848]\n",
      "[1.         0.75511042]\n",
      "[1.         0.79145166]\n",
      "[0.         0.80984863]\n",
      "[1.         0.83486768]\n",
      "[1.         0.74124894]\n",
      "[1.         0.74728888]\n",
      "[4.         0.54746781]\n",
      "[1.         0.86477282]\n",
      "[1.         0.67508261]\n",
      "[4.        0.6940267]\n",
      "[4.         0.64835057]\n",
      "[0.         0.69024059]\n",
      "[4.         0.69044485]\n",
      "[1.        0.8605144]\n",
      "[0.         0.49233591]\n",
      "[0.         0.77990171]\n",
      "[0.         0.71496817]\n",
      "[0.         0.70298619]\n",
      "[1.         0.81719486]\n",
      "[4.         0.58457395]\n",
      "[0.         0.81735386]\n",
      "[1.         0.80628054]\n",
      "[3.         0.68753999]\n",
      "[1.         0.64814716]\n",
      "[4.         0.65456081]\n",
      "[4.         0.58574232]\n",
      "[4.         0.69035499]\n",
      "[4.         0.48080476]\n",
      "[3.         0.63291151]\n",
      "[3.         0.70070041]\n",
      "[1.         0.74478468]\n",
      "[3.         0.77705586]\n",
      "[0.         0.78295241]\n",
      "[1.         0.73370739]\n",
      "[3.         0.58394412]\n",
      "[4.         0.78441768]\n",
      "[1.         0.76475465]\n",
      "[1.       0.806235]\n",
      "[0.         0.64745466]\n",
      "[0.         0.56553266]\n",
      "[3.         0.71456728]\n",
      "[1.         0.75960962]\n",
      "[1.         0.72405703]\n",
      "[4.         0.70835252]\n",
      "[1.        0.5553468]\n",
      "[4.         0.67040577]\n",
      "[1.         0.77138872]\n",
      "[4.         0.80781079]\n",
      "[3.         0.77203408]\n",
      "[0.         0.73553579]\n",
      "[4.         0.39481495]\n",
      "[3.         0.93402454]\n",
      "[4.       0.765189]\n",
      "[4.        0.6725778]\n",
      "[1.         0.71117055]\n",
      "[1.         0.63996561]\n",
      "[1.         0.85015889]\n",
      "[0.        0.6194671]\n",
      "[1.         0.48173553]\n",
      "[4.         0.88669743]\n",
      "[0.         0.86539695]\n",
      "[1.         0.81431012]\n",
      "[3.         0.67598366]\n",
      "[1.         0.74968267]\n",
      "[1.         0.76622436]\n",
      "[3.         0.81011111]\n",
      "[3.        0.6617091]\n",
      "[1.         0.75251099]\n",
      "[4.         0.65038076]\n",
      "[3.         0.58359524]\n",
      "[3.         0.69278829]\n",
      "[4.         0.62286834]\n",
      "[1.         0.62409667]\n",
      "[1.         0.80710797]\n",
      "[1.         0.80986248]\n",
      "[3.         0.75626347]\n",
      "[3.         0.65191306]\n",
      "[4.         0.76556318]\n",
      "[1.         0.87273146]\n",
      "[3.         0.68143401]\n",
      "[1.         0.76802572]\n",
      "[4.         0.67580936]\n",
      "[1.         0.70003766]\n",
      "[1.         0.81846502]\n",
      "[0.         0.64362889]\n",
      "[3.         0.82568717]\n",
      "[4.         0.85994203]\n",
      "[1.         0.85994476]\n",
      "[3.         0.83658956]\n",
      "[1.        0.7369043]\n",
      "[1.         0.65948114]\n",
      "[1.         0.74684393]\n",
      "[3.         0.85711858]\n",
      "[3.         0.80566722]\n",
      "[3.        0.7418252]\n",
      "[1.         0.72345568]\n",
      "[0.         0.75440753]\n",
      "[3.        0.8055289]\n",
      "[0.         0.67559442]\n",
      "[4.         0.63439338]\n",
      "[4.         0.76004682]\n",
      "[3.         0.74707401]\n",
      "[1.         0.80758111]\n",
      "[1.         0.81432014]\n",
      "[3.         0.60198237]\n",
      "[1.        0.6201746]\n",
      "[0.         0.67320378]\n",
      "[1.         0.64214431]\n",
      "[1.         0.75961651]\n",
      "[1.         0.80860453]\n",
      "[4.         0.76950049]\n",
      "[4.         0.53319567]\n",
      "[3.         0.71943306]\n",
      "[1.         0.69003472]\n",
      "[3.         0.79339658]\n",
      "[1.         0.82501473]\n",
      "[0.         0.60827738]\n",
      "[1.         0.78150872]\n",
      "[1.         0.64212278]\n",
      "[0.         0.69743592]\n",
      "[0.         0.74471155]\n",
      "[1.         0.65735794]\n",
      "[0.         0.63806722]\n",
      "[1.         0.60143397]\n",
      "[3.        0.8632195]\n",
      "[1.         0.78779223]\n",
      "[4.         0.83666493]\n",
      "[1.         0.57237628]\n",
      "[4.         0.66878887]\n",
      "[1.         0.67073239]\n",
      "[1.         0.68881922]\n",
      "[3.         0.54349124]\n",
      "[0.         0.59336383]\n",
      "[1.         0.87572854]\n",
      "[1.         0.67994683]\n",
      "[1.         0.79984057]\n",
      "[1.         0.81527669]\n",
      "[3.        0.9012731]\n",
      "[2.00000000e+00 2.10139874e-10]\n",
      "[1.        0.7836019]\n",
      "[3.         0.80437074]\n",
      "[3.         0.64100169]\n",
      "[1.         0.87401313]\n",
      "[1.         0.84597397]\n",
      "[1.         0.74447541]\n",
      "[1.         0.57864744]\n",
      "[4.         0.83391709]\n",
      "[0.         0.89077452]\n",
      "[1.         0.82096401]\n",
      "[1.         0.59139124]\n",
      "[1.         0.78436887]\n",
      "[1.         0.71600892]\n",
      "[1.         0.91484185]\n",
      "[4.         0.56280434]\n",
      "[4.         0.70075894]\n",
      "[0.         0.59735687]\n",
      "[3.         0.64223572]\n",
      "[1.         0.75000073]\n",
      "[1.         0.63304437]\n",
      "[0.         0.75028783]\n",
      "[1.         0.74395305]\n",
      "[4.         0.76299897]\n",
      "[1.         0.67668142]\n",
      "[1.         0.86226796]\n",
      "[1.         0.73818182]\n",
      "[1.       0.532209]\n",
      "[4.      0.67206]\n",
      "[4.         0.55604002]\n",
      "[4.         0.57970118]\n",
      "[4.         0.71493805]\n",
      "[1.         0.66509433]\n",
      "[4.         0.70875906]\n",
      "[1.         0.90753318]\n",
      "[1.         0.77913989]\n",
      "[1.         0.76888546]\n",
      "[1.        0.7032228]\n",
      "[1.         0.65633841]\n",
      "[3.         0.70442828]\n",
      "[1.         0.61323143]\n",
      "[3.         0.76682086]\n",
      "[3.         0.83137532]\n",
      "[1.         0.65209261]\n",
      "[0.         0.79936519]\n",
      "[4.         0.44147965]\n",
      "[1.         0.68457978]\n",
      "[3.        0.8054055]\n",
      "[0.         0.70711779]\n",
      "[3.         0.79615023]\n",
      "[1.         0.76007363]\n",
      "[1.         0.76935489]\n",
      "[1.       0.608913]\n",
      "[4.         0.68371621]\n",
      "[3.         0.62749706]\n",
      "[1.         0.66631809]\n",
      "[1.         0.67320062]\n",
      "[0.         0.55543825]\n",
      "[1.         0.77855151]\n",
      "[1.         0.73753165]\n",
      "[0.       0.694664]\n",
      "[1.         0.78893753]\n",
      "[1.         0.67972136]\n",
      "[1.         0.69315425]\n",
      "[1.         0.71548911]\n",
      "[2.00000000e+00 2.59514762e-08]\n",
      "[3.         0.72349238]\n",
      "[1.         0.65757978]\n",
      "[1.         0.79242993]\n",
      "[1.         0.79197221]\n",
      "[4.         0.75394922]\n",
      "[0.         0.63206081]\n",
      "[1.        0.4082516]\n",
      "[4.         0.58663873]\n",
      "[0.         0.73504856]\n"
     ]
    }
   ],
   "source": [
    "print (centroids)\n",
    "for i in clusters: #HG code clusters\n",
    "    print (i)\n",
    "    # we see that we have 5 clusters within data, ranging from 0 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=500,\n",
      "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=1)\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5, max_iter=500, verbose=1) # initialization\n",
    "print(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 87119978.60946809\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 87119978.60946809\n",
      "center shift 0.000000e+00 within tolerance 1.186616e-01\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 87119978.60946809\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 87119978.60946809\n",
      "center shift 0.000000e+00 within tolerance 1.186616e-01\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 87119978.60946809\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 87119978.60946809\n",
      "center shift 0.000000e+00 within tolerance 1.186616e-01\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 87119978.60946809\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 87119978.60946809\n",
      "center shift 0.000000e+00 within tolerance 1.186616e-01\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 87119978.60946809\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 87119978.60946809\n",
      "center shift 0.000000e+00 within tolerance 1.186616e-01\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 87119978.60946809\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 87119978.60946809\n",
      "center shift 0.000000e+00 within tolerance 1.186616e-01\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 87119978.60946809\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 87119978.60946809\n",
      "center shift 0.000000e+00 within tolerance 1.186616e-01\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 87119978.60946809\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 87119978.60946809\n",
      "center shift 0.000000e+00 within tolerance 1.186616e-01\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 87119978.60946809\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 87119978.60946809\n",
      "center shift 0.000000e+00 within tolerance 1.186616e-01\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 87119978.60946809\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 87119978.60946809\n",
      "center shift 0.000000e+00 within tolerance 1.186616e-01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=500,\n",
       "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=1)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(TFIDF_train_2) # run kmeans on training data set using sklearn without term ferq doc, was causing all \n",
    "#clusters to be 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_2 = kmeans.predict(TFIDF_train_2) #predict values for clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 2000)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clusters_2) \n",
    "clusters.shape\n",
    "target = y_train.T\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#2D\n",
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "\n",
    "print (completeness_score(target[0],clusters[0]))\n",
    "#code was erroring out unless I selected 1 column from each input selected \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print (homogeneity_score(target[0],clusters[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part e run testing based on former clusters labels \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
